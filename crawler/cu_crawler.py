import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import re
import os
import time

try:
    from supabase import create_client, Client
except ImportError:
    from supabase import create_client

class CUCrawler:
    def __init__(self):
        supabase_url = os.getenv('SUPABASE_URL')
        supabase_key = os.getenv('SUPABASE_SERVICE_KEY')
        
        if not supabase_url or not supabase_key:
            raise Exception("Supabase í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        try:
            self.supabase = create_client(supabase_url, supabase_key)
        except TypeError:
            self.supabase = create_client(
                supabase_url=supabase_url,
                supabase_key=supabase_key
            )
        
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
        }
        self.brand_id = 1
    
    def crawl(self):
        print("ğŸª CU í¬ë¡¤ë§ ì‹œì‘...")
        
        url = "https://cu.bgfretail.com/product/product.do?category=product&depth2=6&sf=N"
        
        try:
            print(f"\nğŸ” ì ‘ì† ì¤‘: {url}")
            response = requests.get(url, headers=self.headers, timeout=30)
            response.raise_for_status()
            
            print(f"âœ“ ì‘ë‹µ ì½”ë“œ: {response.status_code}")
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ì„ íƒì ì‹œë„
            items = soup.select('div[class*="prod"] li')
            print(f"ğŸ“¦ ë°œê²¬ëœ ìƒí’ˆ: {len(items)}ê°œ\n")
            
            if items:
                # ì²« ë²ˆì§¸ ìƒí’ˆì˜ HTML êµ¬ì¡° ì¶œë ¥ (ë””ë²„ê¹…ìš©)
                print("="*60)
                print("ğŸ” ì²« ë²ˆì§¸ ìƒí’ˆ HTML êµ¬ì¡°:")
                print("="*60)
                print(items[0].prettify()[:2000])
                print("="*60)
                print()
            
            products = self.parse_items(items, url)
            return products
            
        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def parse_items(self, items, base_url):
        """ì œí’ˆ ì•„ì´í…œ íŒŒì‹± - ìƒì„¸ ë””ë²„ê¹…"""
        products = []
        
        for idx, item in enumerate(items[:5]):  # ì²˜ìŒ 5ê°œë§Œ
            print(f"\n--- ìƒí’ˆ {idx+1} íŒŒì‹± ì‹œë„ ---")
            
            try:
                # ëª¨ë“  í…ìŠ¤íŠ¸ ì¶œë ¥
                all_text = item.get_text(strip=True)
                print(f"ì „ì²´ í…ìŠ¤íŠ¸: {all_text[:100]}")
                
                # ì œí’ˆëª… ì°¾ê¸° - ë‹¤ì–‘í•œ ì„ íƒì ì‹œë„
                title = None
                title_attempts = [
                    ('ê°•', item.select_one('strong')),
                    ('ì´ë¦„', item.select_one('.prodName')),
                    ('ì´ë¦„2', item.select_one('.prod_name')),
                    ('ì´ë¦„3', item.select_one('.name')),
                    ('dt', item.select_one('dt')),
                    ('h3', item.select_one('h3')),
                    ('a.title', item.select_one('a')
.get('title') if item.select_one('a') else None),
                ]
                
                for label, elem in title_attempts:
                    if elem:
                        if isinstance(elem, str):
                            title = elem
                        else:
                            title = elem.text.strip()
                        if title and len(title) > 2:
                            print(f"âœ“ ì œí’ˆëª… ë°œê²¬ ({label}): {title}")
                            break
                
                if not title:
                    # í…ìŠ¤íŠ¸ ì „ì²´ì—ì„œ ì¶”ì¶œ ì‹œë„
                    lines = [line.strip() for line in all_text.split('\n') if line.strip()]
                    if lines:
                        title = lines[0]
                        print(f"âš  ì œí’ˆëª… ì¶”ì¸¡: {title}")
                
                # ê°€ê²© ì°¾ê¸°
                price = None
                price_text = None
                
                price_elems = [
                    item.select_one('.price'),
                    item.select_one('dd'),
                    item.select_one('.val'),
                ]
                
                for elem in price_elems:
                    if elem:
                        price_text = elem.text.strip()
                        break
                
                if not price_text:
                    # ìˆ«ìê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ ì°¾ê¸°
                    import re
                    numbers = re.findall(r'\d{1,3}(?:,\d{3})*', all_text)
                    if numbers:
                        price_text = numbers[0]
                
                if price_text:
                    price_match = re.findall(r'\d+', price_text.replace(',', ''))
                    if price_match:
                        price = int(''.join(price_match))
                        print(f"âœ“ ê°€ê²© ë°œê²¬: {price}ì› (ì›ë³¸: {price_text})")
                
                # ì´ë¯¸ì§€ ì°¾ê¸°
                img = item.select_one('img')
                image_url = None
                if img:
                    image_url = img.get('src') or img.get('data-src')
                    if image_url and not image_url.startswith('http'):
                        if image_url.startswith('//'):
                            image_url = 'https:' + image_url
                        elif image_url.startswith('/'):
                            image_url = 'https://cu.bgfretail.com' + image_url
                    print(f"âœ“ ì´ë¯¸ì§€: {image_url[:50]}...")
                
                # ë§í¬ ì°¾ê¸°
                link = item.select_one('a')
                source_url = base_url
                if link and link.get('href'):
                    href = link.get('href')
                    if href.startswith('http'):
                        source_url = href
                    elif href.startswith('/'):
                        source_url = 'https://cu.bgfretail.com' + href
                
                # ì œí’ˆ ë°ì´í„° ìƒì„±
                if title and len(title) > 2:
                    product = {
                        'brand_id': self.brand_id,
                        'title': title,
                        'normalized_title': self.normalize_title(title),
                        'price': price,
                        'category': self.categorize(title),
                        'launch_date': datetime.now().date().isoformat(),
                        'image_url': image_url,
                        'source_url': source_url,
                        'is_active': True
                    }
                    products.append(product)
                    print(f"âœ… íŒŒì‹± ì„±ê³µ: {title[:40]}")
                else:
                    print(f"âŒ ì œí’ˆëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                
            except Exception as e:
                print(f"âŒ íŒŒì‹± ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
        
        print(f"\nğŸ“Š ìµœì¢… íŒŒì‹± ì„±ê³µ: {len(products)}ê°œ")
        return products
    
    def normalize_title(self, title):
        normalized = re.sub(r'\s+', ' ', title)
        normalized = re.sub(r'[^\w\sê°€-í£]', '', normalized)
        return normalized.strip().upper()
    
    def categorize(self, title):
        title_lower = title.lower()
        keywords = {
            'ìŒë£Œ': ['ìŒë£Œ', 'ì£¼ìŠ¤', 'ì»¤í”¼', 'ìš°ìœ ', 'ì°¨', 'ì›Œí„°', 'ì‚¬ì´ë‹¤', 'ì½œë¼', 'ì—ì´ë“œ'],
            'ê³¼ì': ['ê³¼ì', 'ì´ˆì½œë¦¿', 'ì‚¬íƒ•', 'ì ¤ë¦¬', 'ì¿ í‚¤', 'ë¹„ìŠ¤í‚·', 'ìŠ¤ë‚µ', 'ì¹©'],
            'ì¦‰ì„ì‹í’ˆ': ['ë„ì‹œë½', 'ê¹€ë°¥', 'ìƒŒë“œìœ„ì¹˜', 'ì‚¼ê°ê¹€ë°¥', 'í•«ë„ê·¸', 'í–„ë²„ê±°'],
            'ë¼ë©´': ['ë¼ë©´', 'ì»µë¼ë©´', 'ì§œíŒŒê²Œí‹°', 'ì§œì¥ë©´', 'ë³¶ìŒë©´'],
            'ì•„ì´ìŠ¤í¬ë¦¼': ['ì•„ì´ìŠ¤í¬ë¦¼', 'ë¹™ê³¼', 'ì•„ì´ìŠ¤ë°”', 'ì½˜', 'íŒŒì¸íŠ¸']
        }
        for category, words in keywords.items():
            if any(word in title_lower for word in words):
                return category
        return 'ê¸°íƒ€'
    
    def save_to_db(self, products):
        if not products:
            print("ğŸ’¤ ìˆ˜ì§‘ëœ ì œí’ˆ ì—†ìŒ")
            return 0
        
        print(f"\nğŸ’¾ DB ì €ì¥ ì‹œì‘...")
        
        try:
            thirty_days_ago = (datetime.now() - timedelta(days=30)).date().isoformat()
            existing = self.supabase.table('new_products')\
                .select('normalized_title, launch_date')\
                .eq('brand_id', self.brand_id)\
                .gte('launch_date', thirty_days_ago)\
                .execute()
            
            existing_keys = {
                f"{p['normalized_title']}_{p['launch_date']}" 
                for p in existing.data
            }
            
            new_products = [
                p for p in products 
                if f"{p['normalized_title']}_{p['launch_date']}" not in existing_keys
            ]
            
            if new_products:
                self.supabase.table('new_products').insert(new_products).execute()
                print(f"âœ… {len(new_products)}ê°œ ì‹ ì œí’ˆ ì €ì¥ ì™„ë£Œ")
                for p in new_products[:5]:
                    print(f"  - {p['title'][:40]}")
                if len(new_products) > 5:
                    print(f"  ... ì™¸ {len(new_products)-5}ê°œ")
                return len(new_products)
            else:
                print("â„¹ï¸  ì‹ ê·œ ì œí’ˆ ì—†ìŒ (ëª¨ë‘ ê¸°ì¡´ ì œí’ˆ)")
                return 0
                
        except Exception as e:
            print(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return 0

def main():
    print("="*60)
    print("ğŸª í¸ì˜ì  ì‹ ì œí’ˆ í¬ë¡¤ëŸ¬ ì‹œì‘ (ë””ë²„ê·¸ ëª¨ë“œ)")
    print(f"â° ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    try:
        crawler = CUCrawler()
        products = crawler.crawl()
        new_count = crawler.save_to_db(products)
        print("\n" + "="*60)
        print(f"âœ¨ í¬ë¡¤ë§ ì™„ë£Œ!")
        print(f"ğŸ“Š ìˆ˜ì§‘: {len(products)}ê°œ | ì‹ ê·œ: {new_count}ê°œ")
        print("="*60)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        exit(1)

if __name__ == "__main__":
    main()
