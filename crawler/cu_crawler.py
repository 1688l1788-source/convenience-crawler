import requests
from bs4 import BeautifulSoup
from supabase import create_client
import os
import time
import re

# --- ì„¤ì • ---
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")

TARGET_CATEGORIES = {'40': 'ì•„ì´ìŠ¤í¬ë¦¼'}
MAX_PAGES = 2
MAX_PRODUCTS = 50

# âœ… ì •í™•í•œ í‚¤ì›Œë“œë¡œ ìˆ˜ì •
CATEGORY_KEYWORDS = {
    'ì•„ì´ìŠ¤í¬ë¦¼': [
        'ì•„ì´ìŠ¤í¬ë¦¼', 'ì•„ì´ìŠ¤', 'ë¹™ê³¼', 'ì†Œë¥´ë² ', 'ì ¤ë¼ë˜',
        'ìƒ¤ë²³', 'ìš”ê±°íŠ¸ë°”', 'ìš”êµ¬ë¥´íŠ¸ë°”', 'ë¹™ìˆ˜', 'ìŠ¤ì¿±',
        'íŒŒì¸íŠ¸', 'íŒŒë¥´í˜', 'ë¶•ì–´ì‹¸ë§Œì½”', 'í•˜ê²', 'ë°°ìŠ¤í‚¨',
        'ë¯¸ë‹ˆì»µ', 'ê·¸ë¦­ìš”ê±°', 'ìš°ìœ ë¯¸ë‹ˆì»µ', 'íˆ¬ê²Œë”'
    ],
}

def crawl_general_products(cat_code, cat_name):
    """ì¼ë°˜ ìƒí’ˆ í¬ë¡¤ë§"""
    print(f"  ğŸ›’ ì¼ë°˜ {cat_name} í¬ë¡¤ë§ ì¤‘...")
    products = []
    
    for page in range(1, MAX_PAGES + 1):
        if len(products) >= MAX_PRODUCTS:
            break
            
        url = "https://cu.bgfretail.com/product/productAjax.do"
        payload = {
            "pageIndex": page,
            "searchMainCategory": cat_code,
            "searchSubCategory": "",
            "listType": 0,
            "searchCondition": "setC",
            "searchUseYn": "N",
            "codeParent": cat_code
        }
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        }

        try:
            response = requests.post(url, data=payload, headers=headers, timeout=10)
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'html.parser')
            items = soup.select("li.prod_list")

            if not items:
                break

            for item in items:
                if len(products) >= MAX_PRODUCTS: break
                product = parse_product(item, cat_name)
                if product:
                    products.append(product)
            
            time.sleep(0.5)

        except Exception as e:
            print(f"    âŒ ìš”ì²­ ì—ëŸ¬: {e}")
    
    print(f"    âœ… ì¼ë°˜ {len(products)}ê°œ ë°œê²¬")
    return products


def crawl_all_pb_products():
    """PB ìƒí’ˆ ì „ì²´ í¬ë¡¤ë§"""
    print(f"\nğŸª PB ì „ì²´ ìƒí’ˆ í¬ë¡¤ë§ ì‹œì‘...")
    products = []
    
    for page in range(1, 10):
        url = "https://cu.bgfretail.com/product/pbAjax.do"
        payload = {
            "pageIndex": page,
            "listType": 0,
            "searchCondition": "setA",
            "searchUseYn": "",
            "gdIdx": "0",
            "searchgubun": "CUG",
            "search1": "",
            "search2": "",
            "searchKeyword": ""
        }
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        }

        try:
            response = requests.post(url, data=payload, headers=headers, timeout=10)
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'html.parser')
            items = soup.select("li.prod_list")

            if not items:
                break

            for item in items:
                product = parse_product(item, None)
                if product:
                    products.append(product)
            
            time.sleep(0.5)

        except Exception as e:
            print(f"    âŒ PB ìš”ì²­ ì—ëŸ¬: {e}")
    
    print(f"  âœ… PB ì „ì²´ {len(products)}ê°œ í¬ë¡¤ë§ ì™„ë£Œ\n")
    return products


def filter_pb_by_keywords(all_pb_products, category_name):
    """ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œë¡œ PB ìƒí’ˆ í•„í„°ë§"""
    keywords = CATEGORY_KEYWORDS.get(category_name, [])
    if not keywords:
        return []
    
    # âœ… ì œì™¸ í‚¤ì›Œë“œ (ì•„ì´ìŠ¤í¬ë¦¼ì´ ì•„ë‹Œ ê²ƒë“¤)
    exclude_keywords = ['ê³ ë¡œì¼€', 'í•«ë°”', 'ë–¡', 'ë§Œë‘', 'ê¹€ë°¥', 'ë„ì‹œë½', 
                        'ìƒŒë“œìœ„ì¹˜', 'í–„', 'ì†Œì‹œì§€', 'ë¼ë©´', 'í•«ë„ê·¸', 'ì¹˜í‚¨']
    
    filtered = []
    for product in all_pb_products:
        title = product.get('title', '').lower()
        
        # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
        if any(ex in title for ex in exclude_keywords):
            continue
        
        # í¬í•¨ í‚¤ì›Œë“œ ì²´í¬
        if any(keyword in title for keyword in keywords):
            filtered_product = {
                "title": product.get("title"),
                "price": product.get("price"),
                "image_url": product.get("image_url"),
                "category": category_name,
                "promotion_type": product.get("promotion_type"),
                "source_url": product.get("source_url"),
                "is_active": product.get("is_active", True),
                "brand_id": product.get("brand_id", 1)
            }
            filtered.append(filtered_product)
    
    return filtered


def parse_product(item, category_name):
    """ê³µí†µ íŒŒì‹± í•¨ìˆ˜"""
    try:
        name_tag = item.select_one(".name p")
        title = name_tag.text.strip() if name_tag else "ì´ë¦„ì—†ìŒ"

        price_tag = item.select_one(".price strong")
        price_text = price_tag.text.strip().replace(",", "").replace("ì›", "") if price_tag else "0"
        price = int(price_text) if price_text.isdigit() else 0

        img_tag = item.select_one("img")
        image_url = ""
        if img_tag:
            image_url = img_tag.get('src') or img_tag.get('data-src') or ""
            if image_url.startswith('//'):
                image_url = f"https:{image_url}"
            elif image_url.startswith('/'):
                image_url = f"https://cu.bgfretail.com{image_url}"

        badge_tag = item.select_one(".badge")
        promotion_type = badge_tag.text.strip() if badge_tag else None

        product_url = "https://cu.bgfretail.com/product/view.do?category=product"
        onclick_div = item.select_one("div[onclick*='view']")
        if onclick_div:
            onclick = onclick_div.get('onclick', '')
            match = re.search(r"view\s*\(\s*(\d+)\s*\)", onclick)
            if match:
                gdIdx = match.group(1)
                product_url = f"https://cu.bgfretail.com/product/view.do?gdIdx={gdIdx}&category=product"

        return {
            "title": title,
            "price": price,
            "image_url": image_url,
            "category": category_name,
            "promotion_type": promotion_type,
            "source_url": product_url,
            "is_active": True,
            "brand_id": 1
        }
    except Exception as e:
        print(f"    âš ï¸ íŒŒì‹± ì—ëŸ¬: {e}")
        return None


def main():
    print("ğŸš€ CU í¬ë¡¤ëŸ¬ ì‹œì‘ (ì¼ë°˜ + PB í†µí•©)")

    if not SUPABASE_URL or not SUPABASE_KEY:
        print("âŒ ì—ëŸ¬: Supabase í™˜ê²½ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    all_pb_products = crawl_all_pb_products()
    total_count = 0

    for cat_code, cat_name in TARGET_CATEGORIES.items():
        print(f"ğŸ“‚ [{cat_name}] ì²˜ë¦¬ ì‹œì‘...")
        
        try:
            supabase.table("new_products").delete().eq("category", cat_name).execute()
            print(f"  ğŸ—‘ï¸  ê¸°ì¡´ {cat_name} ë°ì´í„° ì‚­ì œ")
        except Exception as e:
            print(f"  âš ï¸ ì‚­ì œ ì—ëŸ¬: {e}")
        
        general_items = crawl_general_products(cat_code, cat_name)
        
        print(f"  ğŸ” PB {cat_name} í•„í„°ë§ ì¤‘...")
        pb_items = filter_pb_by_keywords(all_pb_products, cat_name)
        print(f"    âœ… PB {len(pb_items)}ê°œ ë°œê²¬")
        
        if pb_items:
            print(f"  ğŸ“ PB ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
            for i, p in enumerate(pb_items[:3], 1):
                print(f"    {i}. {p.get('title')} | category={p.get('category')}")
        
        all_items = general_items + pb_items
        
        print(f"  ğŸ’¾ ì €ì¥ ì¤‘... (ì¼ë°˜ {len(general_items)} + PB {len(pb_items)} = {len(all_items)}ê°œ)")
        
        saved_count = 0
        for product in reversed(all_items):
            if not product: continue
            try:
                supabase.table("new_products").insert(product).execute()
                saved_count += 1
            except Exception as e:
                print(f"  âš ï¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        total_count += saved_count
        print(f"  âœ… {cat_name} ì™„ë£Œ: {saved_count}ê°œ ì €ì¥\n")

    print(f"ğŸ‰ ì „ì²´ ì™„ë£Œ! ì´ {total_count}ê°œ ìƒí’ˆ ì—…ë°ì´íŠ¸")

if __name__ == "__main__":
    main()
