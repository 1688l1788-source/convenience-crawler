import os
import time
import re
import json
import requests
from bs4 import BeautifulSoup
from supabase import create_client

# ==========================================
# âš™ï¸ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
# ==========================================
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")

# ==========================================
# ğŸ§  í†µí•© ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ê¸° (CU ì—„ê²© ëª¨ë“œ ì ìš©)
# ==========================================
def get_standard_category(title, raw_category=None):
    """
    1. CU: ì›ë³¸ ì¹´í…Œê³ ë¦¬ IDë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì‹ ë¢°í•©ë‹ˆë‹¤.
    2. GS25/CUì‹í’ˆ: í‚¤ì›Œë“œ ë¶„ì„ì„ í•˜ë˜, ì˜¤ë¶„ë¥˜(ì½˜ë”, ì•„ì´ìŠ¤í‹°)ë¥¼ ê°•ë ¥ ì°¨ë‹¨í•©ë‹ˆë‹¤.
    """
    
    # ---------------------------------------------------------
    # [1] CU ì›ë³¸ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì ˆëŒ€ ë¶„ë¥˜ (ê°€ì¥ ì•ˆì „)
    # ---------------------------------------------------------
    if raw_category:
        if raw_category == "ì•„ì´ìŠ¤í¬ë¦¼": 
            return "ì•„ì´ìŠ¤" # CUëŠ” 40ë²ˆ ì¹´í…Œê³ ë¦¬ë§Œ ì•„ì´ìŠ¤ë¡œ ì¸ì •
        if raw_category == "ìŒë£Œ": 
            return "ìŒë£Œ"
        if raw_category == "ê³¼ìë¥˜": 
            return "ê³¼ì/ê°„ì‹"
        if raw_category == "ìƒí™œìš©í’ˆ": 
            return "ìƒí™œìš©í’ˆ"
        if raw_category in ["ê°„í¸ì‹ì‚¬", "ì¦‰ì„ì¡°ë¦¬"]: 
            return "ì‹ì‚¬/ë¼ë©´"
        
        # 'ì‹í’ˆ'(GD_05) ì¹´í…Œê³ ë¦¬ëŠ” ë¼ë©´/í†µì¡°ë¦¼/ì•ˆì£¼ ë“±ì´ ì„ì—¬ ìˆìœ¼ë¯€ë¡œ ì•„ë˜ í‚¤ì›Œë“œ ë¡œì§ìœ¼ë¡œ ë„˜ê¹€
        # ë‹¨, ì—¬ê¸°ì„œë„ 'ì•„ì´ìŠ¤'ë¡œëŠ” ì ˆëŒ€ ë¶„ë¥˜í•˜ì§€ ì•ŠìŒ.

    # ---------------------------------------------------------
    # [2] í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ (GS25 ë° CU 'ì‹í’ˆ' ì¹´í…Œê³ ë¦¬ìš©)
    # ---------------------------------------------------------

    # 1. [ìƒí™œìš©í’ˆ] - ì½˜ë”, ìƒë¦¬ëŒ€, ë°©í–¥ì œ ë“± ì˜¤ë¶„ë¥˜ ë°©ì§€
    if any(k in title for k in [
        'ì½˜ë”', 'ì´ˆë°•í˜•', 'ëŒê¸°í˜•', 'ëŸ¬ë¸Œì ¤', 'í˜ë¡œëª¬', # ì„±ì¸ìš©í’ˆ
        'ì„¬ìœ ', 'íƒˆì·¨', 'ì„¸ì œ', 'í”¼ì£¤', 'ìƒ¤í”„ë€', 'ë‹¤ìš°ë‹ˆ', # ì„¸íƒ/ë°©í–¥
        'ì¹˜ì•½', 'ì¹«ì†”', 'ê°€ê¸€', 'ê°€ê·¸ë¦°', 'í˜ë¦¬ì˜¤', 'ë©”ë””ì•ˆ', '2080', 'ë¦¬ì¹˜', 'ë´íƒˆ', 
        'ë¬¼í‹°ìŠˆ', 'í‹°ìŠˆ', 'ë§ˆìŠ¤í¬', 'ìƒë¦¬ëŒ€', 'ì¤‘í˜•', 'ëŒ€í˜•', 'ì†Œí˜•', 'ì˜¤ë²„ë‚˜ì´íŠ¸', 'íŒ¨ë“œ', 'ë¼ì´ë„ˆ', 'íƒí°', 'íŒ¬í‹°',
        'ë¼ì—˜', 'ì˜í”¼', 'í™”ì´íŠ¸', 'ì¢‹ì€ëŠë‚Œ', 'ì‹œí¬ë¦¿ë°ì´', 'ë””ì–´ìŠ¤í‚¨', 'ìˆœìˆ˜í•œë©´',
        'ìƒ´í‘¸', 'ë¦°ìŠ¤', 'íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸', 'í—¤ì–´', 'ì„¸ëŸ¼', 'ë¹„ëˆ„', 'ì—˜ë¼ìŠ¤í‹´', 'ì¼€ë¼ì‹œìŠ¤', 'ì˜¤ê°€ë‹ˆìŠ¤íŠ¸', 'ë°”ë””ì›Œì‹œ',
        'ë¡œì…˜', 'í•¸ë“œí¬ë¦¼', 'ìˆ˜ë”©ì ¤', 'í´ë Œì§•', 'ì›Œí„°ë§ˆì´ë“œ', 'ì—ì„¼ì…œ', 'ì¡´ìŠ¨ì¦ˆ', 'ì•„ë¹„ë…¸', 'ë‹ˆë² ì•„', 'ë©”ë””í', 'ë¦½ì¼€ì–´', 'ì˜¤ì¼',
        'ë½ìŠ¤', 'ìŠˆê°€ë²„ë¸”', 'íí', 'í”¼ì§€', 'ê±´ì „ì§€', 'ìŠ¤íƒ€í‚¹', 'ë°´ë“œ', 'ì¼íšŒìš©', 'ì œê±°', 'í´ë¦°í•', 'ìš°ì‚°', 'ì–‘ë§'
    ]):
        return "ìƒí™œìš©í’ˆ"

    # 2. [ìŒë£Œ] - ì•„ì´ìŠ¤í‹°, ì½˜íŠ¸ë¼ë² ì´ìŠ¤ ë“± 'ì•„ì´ìŠ¤/ì½˜'ì´ ë“¤ì–´ê°€ëŠ” ìŒë£Œ ë°©ì–´
    if any(k in title for k in [
        'ì•„ì´ìŠ¤í‹°', 'ìš°ìœ ', 'ì»¤í”¼', 'ë¼ë–¼', 'ì•„ë©”ë¦¬ì¹´ë…¸', 'ì½œë¼', 'ì‚¬ì´ë‹¤', 'ì—ì´ë“œ', 'ì£¼ìŠ¤', 'ë³´ë¦¬ì°¨', 'ì˜¥ìˆ˜ìˆ˜ìˆ˜ì—¼ì°¨', 
        'ë¹„íƒ€', 'ë°•ì¹´ìŠ¤', 'ìŒí™”', 'ë‘ìœ ', 'ìš”êµ¬ë¥´íŠ¸', 'ìš”ê±°íŠ¸', 'ë¬¼', 'ì›Œí„°', 'í”„ë¡œí‹´', 'ì½¤ë¶€ì°¨', 'ë“œë§í¬', 'ì´ì˜¨', 
        'í‹°', 'TEA', 'ë°”ë¦¬ìŠ¤íƒ€', 'ì½˜íŠ¸ë¼', 'ì¹´í˜', 'ë§ˆì´ë…¸ë©€', 'ì„œìš¸FB', 'ë§¥ì£¼', 'í•˜ì´ë³¼'
    ]):
        return "ìŒë£Œ"

    # 3. [ì‹ì‚¬/ë¼ë©´]
    # ì •ê·œì‹: "ë°”" ë’¤ì— "ìˆ«ì+g"ê°€ ë¶™ëŠ” íŒ¨í„´ (ì˜ˆ: í•«ë°”80g) -> ì‹í’ˆì„
    is_food_bar_regex = re.search(r'ë°”\s*\d+g', title)
    if is_food_bar_regex or any(k in title for k in [
        'ì§í™”', 'í›„ë‘í¬', 'ê¼¬ì¹˜ë°”', # ìš”ì²­í•˜ì‹  ì‹í’ˆ í‚¤ì›Œë“œ
        'ë„ì‹œë½', 'ê¹€ë°¥', 'ì£¼ë¨¹ë°¥', 'ìƒŒë“œìœ„ì¹˜', 'í–„ë²„ê±°', 'ë¼ë©´', 'ë©´', 'ìš°ë™', 'êµ­ë°¥', 'ì£½', 'íƒ•', 'ì°Œê°œ', 
        'í–‡ë°˜', 'ì»µë°˜', 'í•«ë°”', 'ì†Œì‹œì§€', 'ë§Œë‘', 'ë‹­ê°€ìŠ´ì‚´', 'ì¹˜í‚¨', 'ìœ¡ê°œì¥', 'ê·¸ë˜ë†€ë¼', 'í†µê³¡ë¬¼ë°¥', 'í¬ë©', 'íŠ€ê¹€', 'ë¸Œë¦¬ë˜', 'íŒŒìŠ¤íƒ€', 
        '3XL', 'í‚¬ë°”ì‚¬', 'ì˜¤ì§•ì–´', 'ë°¥ë°”', 'ë²„ê±°', 'ìƒëŸ¬ë“œ', 'ì•¼ë¼ì†Œë°”', 'ë² ì´ì»¨', 'ìŠ¤í…Œì´í¬'
    ]):
        return "ì‹ì‚¬/ë¼ë©´"

    # 4. [ê³¼ì/ê°„ì‹] - ê¼¬ê¹”ì½˜, ì½˜í‘¸ë¼ì´íŠ¸ ë“± 'ì½˜' ë°©ì–´
    if any(k in title for k in [
        'ê¼¬ê¹”ì½˜', 'ì½˜ì´ˆ', 'ì½˜í‘¸ë¼ì´íŠ¸', 'ì˜¤ê³¡ì½”ì½”ë³¼', 'í¬ëŸ°í‚¤', 'ììœ ì‹œê°„', 'í‚¤ì»¤', 'í‚¤ì„¸ìŠ¤', 'ì´ˆì½”ë°”', 'ì—ë„ˆì§€ë°”',
        'ìŠ¤ë‚µ', 'ì ¤ë¦¬', 'ì‚¬íƒ•', 'ê»Œ', 'ì´ˆì½”', 'ì¿ í‚¤', 'ì¹©', 'ë¹µ', 'ì¼€ìµ', 'ì•½ê³¼', 'ì–‘ê°±', 'í”„ë ˆì²¼', 'íŒì½˜', 
        'ì•„ëª¬ë“œ', 'ìœ¡í¬', 'ì–´ë¬µ', 'ë§›ë°¤', 'ë§ì°¨ë¹µ', 'í—ˆì‰¬', 'ê·¸ë¦­ìš”ê±°íŠ¸', 'ì˜¤íŒœ', 'í‘¸ë”©', 'ë””ì €íŠ¸', 'í‚·ìº£', 'ë„ë„›'
    ]):
        return "ê³¼ì/ê°„ì‹"

    # 5. [ì•„ì´ìŠ¤] (GS25ìš©, í˜¹ì€ CUì˜ ì¹´í…Œê³ ë¦¬ê°€ ë¶ˆë¶„ëª…í•  ë•Œ)
    # CUì˜ ê²½ìš° ì´ë¯¸ ìœ„ì—ì„œ raw_categoryë¡œ ê±¸ëŸ¬ì¡Œìœ¼ë¯€ë¡œ, ì—¬ê¸°ëŠ” GS25ë‚˜ ë¶„ë¥˜ ë¶ˆê°€ëŠ¥í•œ ìƒí’ˆë§Œ ë„ë‹¬í•¨.
    # í•˜ì§€ë§Œ CU 'ì‹í’ˆ' ì¹´í…Œê³ ë¦¬ì— ì•„ì´ìŠ¤í¬ë¦¼ì´ ì„ì—¬ìˆì„ í™•ë¥ ì€ ë‚®ìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ í•„í„°ë§.
    if raw_category == "ì‹í’ˆ":
        # CU ì‹í’ˆ ì¹´í…Œê³ ë¦¬ ì•ˆì—ëŠ” ì•„ì´ìŠ¤í¬ë¦¼ì´ ì—†ë‹¤ê³  ê°€ì •í•˜ê³  ê¸°íƒ€ë‚˜ ì‹ì‚¬ë¡œ ë³´ëƒ„
        return "ì‹ì‚¬/ë¼ë©´"

    if any(k in title for k in [
        'í•˜ê²', 'ì†Œë¥´ë² ', 'ë¼ë¼ìŠ¤ìœ—', 'ë‚˜ëšœë£¨', 'ë²¤ì•¤', # ë¬´ì¡°ê±´ ì•„ì´ìŠ¤ ë¸Œëœë“œ
        'ì•„ì´ìŠ¤', 'ì½˜', 'íŒŒì¸íŠ¸', 'ì„¤ë ˆì„', 'í´ë¼í¬', 'ìŠ¤í¬ë¥˜', 'ë¼ì§€ë°”', 'ë¹™ìˆ˜', 'ìƒ¤ë² íŠ¸', 'ì°°ì˜¥ìˆ˜ìˆ˜',
        'ë¯¸ë‹ˆì»µ', 'ë¹„ë¹„ë¹…', 'ë©”ë¡œë‚˜', 'ëˆ„ê°€ë°”', 'ìŒìŒë°”', 'ë°”ë°¤ë°”', 'ì˜¥ë™ì', 'ì™€ì¼ë“œë°”ë””', 'ë¶•ì–´ì‹¸ë§Œì½”', 
        'ë”ìœ„ì‚¬ëƒ¥', 'ë¹µë¹ ë ˆ', 'êµ¬ìŠ¬', 'íƒ±í¬ë³´ì´', 'ë¹ ì‚ì½”', 'ìš”ë§˜ë•Œ', 'ì¿ ì•¤í¬', 'ìˆ˜ë°•ë°”', 'ì£ ìŠ¤ë°”', 
        'ì œë¡œìœ—', 'ë¡œìš°ìœ—', 'ì„œì£¼', 'ë™ê·¸ë¦°', 'ì‚¼ìš°', 'íŒŒë¥´í˜', 'ì¿¨ë¦¬ì‰¬'
    ]):
        return "ì•„ì´ìŠ¤"

    return "ê¸°íƒ€"

# ==========================================
# ğŸª 1. CU í¬ë¡¤ë§ (NEW ë¼ë²¨ í¬í•¨, ì¹´í…Œê³ ë¦¬ ì—„ìˆ˜)
# ==========================================
def parse_cu_product(item, raw_cat_name):
    try:
        # 1. ì œëª©
        name_tag = item.find("div", class_="name")
        if not name_tag: return None
        title = name_tag.get_text(strip=True)
        
        # [ì œì™¸] GETì»¤í”¼ ë“± ì œì™¸
        if "GET" in title and ("ì•„ë©”ë¦¬ì¹´ë…¸" in title or "ë¼ë–¼" in title or "ì»¤í”¼" in title): 
            return None

        # 2. ê°€ê²©
        price_tag = item.find("div", class_="price")
        price = 0
        if price_tag:
            strong = price_tag.find("strong")
            if strong:
                price = int(strong.get_text(strip=True).replace(",", ""))

        # 3. ì´ë¯¸ì§€
        img_tag = item.find("img")
        img_src = ""
        if img_tag:
            img_src = img_tag.get("src") or ""
            if img_src and not img_src.startswith("http"):
                if img_src.startswith("//"): img_src = "https:" + img_src
                else: img_src = "https://cu.bgfretail.com" + img_src

        # 4. [NEW ë¼ë²¨ ìˆ˜ì§‘]
        badge_tag = item.find("div", class_="badge")
        promo = "ì¼ë°˜"
        if badge_tag:
            # 1+1, 2+1, NEW ë“± í…ìŠ¤íŠ¸ ì¶”ì¶œ
            span = badge_tag.find("span")
            if span:
                promo = span.get_text(strip=True)
            else:
                promo = badge_tag.get_text(strip=True)
        
        # ë¤ì¦ì • ì œì™¸
        if "ë¤" in promo or "ì¦ì •" in promo:
            return None

        # 5. ID ì¶”ì¶œ
        gdIdx = None
        onclick = item.find("div", onclick=re.compile(r"view\("))
        if onclick:
            m = re.search(r"view\s*\(\s*['\"]?(\d+)['\"]?\s*\)", onclick.get('onclick'))
            if m: gdIdx = int(m.group(1))
        
        # ë°±ì—… ë°©ì‹ (a íƒœê·¸)
        if not gdIdx:
            photo_div = item.find("div", class_="photo")
            if photo_div and photo_div.find("a"):
                onclick = photo_div.find("a").get("onclick") or ""
                m = re.search(r"view\s*\(\s*['\"]?(\d+)['\"]?\s*\)", onclick)
                if m: gdIdx = int(m.group(1))

        if not gdIdx: return None

        # ì¹´í…Œê³ ë¦¬ ê²°ì •
        std_category = get_standard_category(title, raw_cat_name)

        return {
            "title": title,
            "price": price,
            "image_url": img_src,
            "category": std_category,
            "original_category": raw_cat_name,
            "promotion_type": promo, # NEW, 1+1 ë“± ê·¸ëŒ€ë¡œ ì €ì¥
            "brand_id": 1,
            "source_url": f"https://cu.bgfretail.com/product/view.do?category=product&gdIdx={gdIdx}",
            "is_active": True,
            "external_id": gdIdx
        }
    except: return None

def crawl_cu(supabase):
    print("\nğŸš€ CU í¬ë¡¤ë§ ì‹œì‘...")
    
    # ì „ì²´ ì‚­ì œ í›„ ê°±ì‹ 
    supabase.table("new_products").delete().eq("brand_id", 1).execute()

    cu_categories = [
        {"id": "40", "name": "ì•„ì´ìŠ¤í¬ë¦¼"},
        {"id": "10", "name": "ê°„í¸ì‹ì‚¬"},
        {"id": "30", "name": "ê³¼ìë¥˜"},
        {"id": "50", "name": "ì‹í’ˆ"},
        {"id": "60", "name": "ìŒë£Œ"},
        {"id": "70", "name": "ìƒí™œìš©í’ˆ"}
    ]
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "Referer": "https://cu.bgfretail.com"
    }
    
    all_cu_items = []
    
    for cat in cu_categories:
        print(f"ğŸ” CU ì¡°íšŒ: {cat['name']} (ID: {cat['id']})")
        
        # listType: 0 (ì „ì²´ ìƒí’ˆ) - ì‹ ìƒ, í–‰ì‚¬, ì¼ë°˜ ëª¨ë‘ í¬í•¨
        for page in range(1, 21):
            try:
                r = requests.post("https://cu.bgfretail.com/product/productAjax.do", 
                                data={"pageIndex": page, "searchMainCategory": cat['id'], "listType": 0},
                                headers=headers, timeout=10)
                r.encoding = 'utf-8'
                soup = BeautifulSoup(r.text, "html.parser")
                items = soup.select("li.prod_list")
                
                if not items: break
                
                count = 0
                for item in items:
                    p = parse_cu_product(item, cat['name'])
                    if p:
                        all_cu_items.append(p)
                        count += 1
                
                if count == 0: break
                time.sleep(0.1)
            except Exception as e:
                print(f"   âŒ ì—ëŸ¬: {e}")
                break

    if len(all_cu_items) > 0:
        print(f"âœ… CU ì´ {len(all_cu_items)}ê°œ ìˆ˜ì§‘ ì„±ê³µ. DB ì €ì¥ ì¤‘...")
        try:
            unique_items = {p['external_id']: p for p in all_cu_items}.values()
            items_list = list(unique_items)
            
            for i in range(0, len(items_list), 100):
                supabase.table("new_products").insert(items_list[i:i+100]).execute()
            print("ğŸ‰ CU ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        except Exception as e:
            print(f"âŒ CU ì €ì¥ ì‹¤íŒ¨: {e}")
    else:
        print("ğŸ˜± ê²½ê³ : CU ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# ==========================================
# ğŸª 2. GS25 í¬ë¡¤ë§ (ë¤ì¦ì • ì œì™¸)
# ==========================================
def get_gs25_token():
    session = requests.Session()
    session.headers.update({
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Referer": "https://gs25.gsretail.com/gscvs/ko/products/event-goods",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
    })
    for i in range(3):
        try:
            r = session.get("https://gs25.gsretail.com/gscvs/ko/products/event-goods", timeout=15)
            soup = BeautifulSoup(r.text, "html.parser")
            token_input = soup.find("input", {"name": "CSRFToken"})
            if token_input and token_input.get('value'):
                return session, token_input['value']
            m = re.search(r"CSRFToken\s*[:=]\s*['\"]([^'\"]+)['\"]", r.text)
            if m: return session, m.group(1)
            time.sleep(1)
        except: time.sleep(1)
    return session, None

def crawl_gs25(supabase):
    print("\nğŸš€ GS25 í¬ë¡¤ë§ ì‹œì‘...")
    session, token = get_gs25_token()
    if not token:
        print("âŒ GS25 í† í° íšë“ ì‹¤íŒ¨.")
        return

    print(f"   ğŸ”‘ í† í° íšë“ ì„±ê³µ ({token[:10]}...)")
    
    session.headers.update({
        "Accept": "application/json, text/javascript, */*; q=0.01",
        "X-Requested-With": "XMLHttpRequest",
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "Origin": "https://gs25.gsretail.com"
    })

    all_gs_items = []
    # GIFT ì œì™¸
    promo_types = ["ONE_TO_ONE", "TWO_TO_ONE"] 
    promo_map = {"ONE_TO_ONE": "1+1", "TWO_TO_ONE": "2+1"}

    for p_type in promo_types:
        print(f"ğŸ” GS25 ì¡°íšŒ: {p_type}")
        for page in range(1, 20):
            try:
                url = "https://gs25.gsretail.com/gscvs/ko/products/event-goods-search"
                payload = {
                    "CSRFToken": token, "pageNum": str(page), "pageSize": "50", 
                    "parameterList": p_type
                }
                r = session.post(url, data=payload, timeout=10)
                try: data = r.json()
                except: data = json.loads(r.text)
                if isinstance(data, str): data = json.loads(data)
                
                results = data.get("results", [])
                if not results: break
                
                for item in results:
                    title = item.get("goodsNm", "").strip()
                    price = int(item.get("price", 0))
                    att_id = item.get("attFileId", "")
                    id_match = re.search(r'(\d+)', att_id)
                    ext_id = int(id_match.group(1)[-18:]) if id_match else int(time.time()*1000)
                    
                    all_gs_items.append({
                        "title": title,
                        "price": int(item.get("price", 0)),
                        "image_url": item.get("attFileNm", ""),
                        "category": get_standard_category(title, None),
                        "original_category": None,
                        "promotion_type": promo_map.get(p_type, "í–‰ì‚¬"),
                        "brand_id": 2,
                        "source_url": "http://gs25.gsretail.com/gscvs/ko/products/event-goods",
                        "is_active": True,
                        "external_id": ext_id
                    })
                time.sleep(0.1)
            except Exception as e: break

    if len(all_gs_items) > 0:
        print(f"âœ… GS25 ì´ {len(all_gs_items)}ê°œ ìˆ˜ì§‘ ì„±ê³µ. ì €ì¥ ì¤‘...")
        try:
            supabase.table("new_products").delete().eq("brand_id", 2).execute()
            
            unique_gs = {p['external_id']: p for p in all_gs_items}.values()
            items_list = list(unique_gs)
            
            for i in range(0, len(items_list), 100):
                supabase.table("new_products").insert(items_list[i:i+100]).execute()
            print("ğŸ‰ GS25 ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        except Exception as e:
            print(f"âŒ GS25 ì €ì¥ ì‹¤íŒ¨: {e}")
    else:
        print("ğŸ˜± ê²½ê³ : GS25 ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# ==========================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰
# ==========================================
def main():
    if not SUPABASE_URL or not SUPABASE_KEY:
        print("âŒ ì„¤ì • ì˜¤ë¥˜: í™˜ê²½ë³€ìˆ˜ ëˆ„ë½")
        return
    
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    # ğŸ§¹ ê¸°ì¡´ ë¤ì¦ì • ë°ì´í„° ì‚­ì œ
    try:
        supabase.table("new_products").delete().or_("promotion_type.eq.ë¤,promotion_type.eq.ë¤ì¦ì •,promotion_type.ilike.%GIFT%").execute()
    except: pass

    crawl_cu(supabase)
    crawl_gs25(supabase)
    
    print("\nğŸ‰ ëª¨ë“  í¬ë¡¤ë§ ì‘ì—… ì™„ë£Œ!")

if __name__ == "__main__":
    main()
