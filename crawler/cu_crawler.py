import os
import time
import re
import requests
from bs4 import BeautifulSoup
from supabase import create_client

SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")

# ì•ˆì „ì¥ì¹˜: ìµœëŒ€ 50í˜ì´ì§€ê¹Œì§€ íƒìƒ‰ (ë³´í†µ 20~30í˜ì´ì§€ë©´ ëë‚¨)
MAX_SEARCH_PAGES = 50 
TARGET_COUNT = 50  # ìµœì¢…ì ìœ¼ë¡œ ì €ì¥í•  ìµœì‹  ìƒí’ˆ ê°œìˆ˜

def parse_product(item):
    try:
        name_tag = item.select_one(".name p")
        title = (name_tag.get_text(strip=True) if name_tag else "").strip()
        
        price_tag = item.select_one(".price strong")
        price_text = (price_tag.get_text(strip=True) if price_tag else "0").replace(",", "").replace("ì›", "")
        price = int(price_text) if price_text.isdigit() else 0

        img_tag = item.select_one("img")
        image_url = ""
        if img_tag:
            image_url = img_tag.get("src") or img_tag.get("data-src") or ""
            if image_url.startswith("//"):
                image_url = "https:" + image_url
            elif image_url.startswith("/"):
                image_url = "https://cu.bgfretail.com" + image_url

        badge_tag = item.select_one(".badge")
        promotion_type = badge_tag.get_text(strip=True) if badge_tag else None

        product_url = "https://cu.bgfretail.com/product/view.do?category=product"
        onclick_div = item.select_one("div[onclick*='view']")
        if onclick_div:
            onclick = onclick_div.get("onclick", "")
            m = re.search(r"view\s*\(\s*(\d+)\s*\)", onclick)
            if m:
                gdIdx = m.group(1)
                product_url = f"https://cu.bgfretail.com/product/view.do?gdIdx={gdIdx}&category=product"
        
        # ì œëª©ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if not title:
            return None

        return {
            "title": title,
            "price": price,
            "image_url": image_url,
            "category": "ì•„ì´ìŠ¤í¬ë¦¼",
            "promotion_type": promotion_type,
            "source_url": product_url,
            "is_active": True,
            "brand_id": 1
        }
    except Exception:
        return None

def fetch_all_icecream():
    all_products = []
    print("ğŸ”„ ì „ì²´ í˜ì´ì§€ ìŠ¤ìº” ì‹œì‘ (ëê¹Œì§€ ì°¾ê¸°)...")
    
    for page in range(1, MAX_SEARCH_PAGES + 1):
        url = "https://cu.bgfretail.com/product/productAjax.do"
        payload = {
            "pageIndex": page,
            "searchMainCategory": "40",
            "listType": 0,
            "searchCondition": "",
        }
        headers = {
            "User-Agent": "Mozilla/5.0",
            "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        }

        try:
            r = requests.post(url, data=payload, headers=headers, timeout=5)
            r.encoding = "utf-8"
            soup = BeautifulSoup(r.text, "html.parser")
            items = soup.select("li.prod_list")

            if not items:
                print(f"  ğŸ›‘ í˜ì´ì§€ {page}: ë°ì´í„° ì—†ìŒ. ì—¬ê¸°ê°€ ë!")
                break
            
            # í˜ì´ì§€ ë‚´ ìƒí’ˆ ìˆ˜ì§‘
            page_products = []
            for item in items:
                p = parse_product(item)
                if p:
                    page_products.append(p)
            
            all_products.extend(page_products)
            print(f"  âœ… í˜ì´ì§€ {page}: {len(page_products)}ê°œ ìˆ˜ì§‘ (ëˆ„ì  {len(all_products)}ê°œ)")
            
            time.sleep(0.1) # ë¹ ë¥´ê²Œ
            
        except Exception as e:
            print(f"  âŒ í˜ì´ì§€ {page} ì—ëŸ¬: {e}")
            break
            
    return all_products

def chunk(lst, size):
    for i in range(0, len(lst), size):
        yield lst[i:i+size]

def main():
    if not SUPABASE_URL or not SUPABASE_KEY:
        raise RuntimeError("í™˜ê²½ë³€ìˆ˜ ì—†ìŒ")

    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

    # 1. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
    supabase.table("new_products").delete().eq("brand_id", 1).execute()

    # 2. ì „ì²´ í¬ë¡¤ë§ (í˜ì´ì§€ 1ë¶€í„° ëê¹Œì§€)
    # ë¦¬ìŠ¤íŠ¸ ìˆœì„œ: [ì˜¤ë˜ëœ ìƒí’ˆ(1í˜ì´ì§€) ..... ìµœì‹  ìƒí’ˆ(ë§ˆì§€ë§‰í˜ì´ì§€)]
    full_list = fetch_all_icecream()

    if not full_list:
        print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 3. ë§ˆì§€ë§‰ 50ê°œë§Œ ìë¥´ê¸° (ì´ê²Œ ì§„ì§œ ìµœì‹  ìƒí’ˆë“¤)
    # ë’¤ì—ì„œ 50ê°œ ìŠ¬ë¼ì´ì‹±
    latest_products = full_list[-TARGET_COUNT:]
    
    print(f"\nâœ‚ï¸ ì „ì²´ {len(full_list)}ê°œ ì¤‘ ìµœì‹  {len(latest_products)}ê°œë§Œ ì„ íƒí•¨.")
    print(f"   - ìµœì‹  1ìœ„ ì˜ˆìƒ: {latest_products[-1]['title']}")
    print(f"   - ìµœì‹  2ìœ„ ì˜ˆìƒ: {latest_products[-2]['title']}")

    # 4. ì €ì¥
    # latest_products ë¦¬ìŠ¤íŠ¸ëŠ” [ëœ ìµœì‹  -> ë” ìµœì‹  -> ê°€ì¥ ìµœì‹ ] ìˆœì„œì„
    # ì´ëŒ€ë¡œ insertí•˜ë©´ IDê°€ ìˆœì„œëŒ€ë¡œ ë¶€ì—¬ë¨ (1 -> 2 -> ... -> 50)
    # ê°€ì¥ ìµœì‹ ì´ ID 50ì´ ë¨.
    # ì•±ì—ì„œ ORDER BY id DESC í•˜ë©´ ID 50(ê°€ì¥ ìµœì‹ )ì´ ë§¨ ìœ„ì— ë‚˜ì˜´. âœ… ì •ë‹µ!
    
    if latest_products:
        try:
            supabase.table("new_products").insert(latest_products).execute()
        except Exception:
            for part in chunk(latest_products, 50): # 50ê°œ í•œë²ˆì—
                supabase.table("new_products").insert(part).execute()

    print(f"\nğŸ‰ ì €ì¥ ì™„ë£Œ! ì•±ì—ì„œ í™•ì¸í•´ë³´ì„¸ìš”.")

if __name__ == "__main__":
    main()
