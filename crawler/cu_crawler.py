import os
import time
import re
import requests
from bs4 import BeautifulSoup
from supabase import create_client

SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")

MAX_SEARCH_PAGES = 100  # ì¶©ë¶„íˆ í¬ê²Œ (ì „ì²´ ìŠ¤ìº”ìš©)

def parse_product(item):
    try:
        name_tag = item.select_one(".name p")
        title = (name_tag.get_text(strip=True) if name_tag else "").strip()
        
        price_tag = item.select_one(".price strong")
        price_text = (price_tag.get_text(strip=True) if price_tag else "0").replace(",", "").replace("ì›", "")
        price = int(price_text) if price_text.isdigit() else 0

        img_tag = item.select_one("img")
        image_url = ""
        if img_tag:
            image_url = img_tag.get("src") or img_tag.get("data-src") or ""
            if image_url.startswith("//"):
                image_url = "https:" + image_url
            elif image_url.startswith("/"):
                image_url = "https://cu.bgfretail.com" + image_url

        badge_tag = item.select_one(".badge")
        promotion_type = badge_tag.get_text(strip=True) if badge_tag else None

        product_url = "https://cu.bgfretail.com/product/view.do?category=product"
        gdIdx = None
        onclick_div = item.select_one("div[onclick*='view']")
        if onclick_div:
            onclick = onclick_div.get("onclick", "")
            m = re.search(r"view\s*\(\s*(\d+)\s*\)", onclick)
            if m:
                gdIdx = int(m.group(1)) # ìˆ«ìí˜•ìœ¼ë¡œ ì €ì¥
                product_url = f"https://cu.bgfretail.com/product/view.do?gdIdx={gdIdx}&category=product"
        
        if not title: return None

        return {
            "title": title,
            "price": price,
            "image_url": image_url,
            "category": "ì•„ì´ìŠ¤í¬ë¦¼",
            "promotion_type": promotion_type,
            "source_url": product_url,
            "is_active": True,
            "brand_id": 1,
            "external_id": gdIdx  # âœ… ì¤‘ë³µ ì²´í¬ìš© ê³ ìœ  ID
        }
    except Exception:
        return None

def main():
    if not SUPABASE_URL or not SUPABASE_KEY:
        raise RuntimeError("í™˜ê²½ë³€ìˆ˜ ì—†ìŒ")

    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    # 1. DBì— ìˆëŠ” ê°€ì¥ ìµœì‹  external_id(gdIdx) ì¡°íšŒ
    # (ì´ ë²ˆí˜¸ë³´ë‹¤ í° ê²ƒë§Œ ìƒˆë¡œ ì¶”ê°€í•˜ë©´ ë¨)
    try:
        last_item = supabase.table("new_products") \
            .select("external_id") \
            .eq("brand_id", 1) \
            .order("external_id", desc=True) \
            .limit(1) \
            .execute()
        
        max_gdIdx = last_item.data[0]['external_id'] if last_item.data else 0
        print(f"ğŸ“Š í˜„ì¬ DB ë§ˆì§€ë§‰ ìƒí’ˆ ë²ˆí˜¸: {max_gdIdx}")
    except Exception:
        max_gdIdx = 0

    new_products = []
    
    # 2. ì „ì²´ í˜ì´ì§€ ìŠ¤ìº” (í˜ì´ì§€ 1ë¶€í„° ëê¹Œì§€ ê°€ë©´ì„œ ë°ì´í„° ìˆ˜ì§‘)
    # CUëŠ” í˜ì´ì§€ 1ì´ ê°€ì¥ ì˜¤ë˜ëœ ê²ƒ -> ë’¤ë¡œ ê°ˆìˆ˜ë¡ ìµœì‹ 
    # ë”°ë¼ì„œ í˜ì´ì§€ 1ë¶€í„° ì­‰ í›‘ìœ¼ë©´ì„œ max_gdIdxë³´ë‹¤ í° ê²ƒë§Œ ë‹´ìœ¼ë©´ ë¨.
    # ë§Œì•½ DBê°€ ë¹„ì–´ìˆìœ¼ë©´(max_gdIdx=0) ì „ì²´ê°€ ë‹¤ ë‹´ê¹€.
    
    print("ğŸ”„ ì—…ë°ì´íŠ¸ ìŠ¤ìº” ì‹œì‘...")
    
    for page in range(1, MAX_SEARCH_PAGES + 1):
        url = "https://cu.bgfretail.com/product/productAjax.do"
        payload = {"pageIndex": page, "searchMainCategory": "40", "listType": 0}
        headers = {"User-Agent": "Mozilla/5.0", "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8"}

        try:
            r = requests.post(url, data=payload, headers=headers, timeout=5)
            soup = BeautifulSoup(r.text, "html.parser")
            items = soup.select("li.prod_list")

            if not items:
                print(f"  ğŸ›‘ í˜ì´ì§€ {page}: ë!")
                break
            
            count_in_page = 0
            for item in items:
                p = parse_product(item)
                if p and p['external_id']:
                    # ì´ë¯¸ ìˆëŠ” ìƒí’ˆ(ë²ˆí˜¸ê°€ ì‘ê±°ë‚˜ ê°™ìŒ)ì€ ìŠ¤í‚µ? 
                    # ì•„ë‹ˆë©´ ê°€ê²© ë³€ë™ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ ë®ì–´ì“°ê¸°?
                    # "ì„œë²„ ë¶€í•˜ ì ê²Œ"ê°€ ëª©í‘œë¼ë©´ ìŠ¤í‚µì´ ë§ìŒ.
                    # í•˜ì§€ë§Œ CU êµ¬ì¡°ìƒ ë’¤í˜ì´ì§€ì— ìƒˆ ìƒí’ˆì´ ë‚˜ì˜¤ë¯€ë¡œ, ì¼ë‹¨ ë‹¤ í›‘ì–´ì•¼ í•¨.
                    
                    if p['external_id'] > max_gdIdx:
                        new_products.append(p)
                        count_in_page += 1
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            if count_in_page > 0:
                print(f"  âœ… í˜ì´ì§€ {page}: ì‹ ìƒí’ˆ {count_in_page}ê°œ ë°œê²¬")
            else:
                # ì´ í˜ì´ì§€ì— ì‹ ìƒí’ˆì´ í•˜ë‚˜ë„ ì—†ë‹¤ë©´?
                # CU êµ¬ì¡°ìƒ: ì• í˜ì´ì§€(1, 2..)ëŠ” ì˜›ë‚  ìƒí’ˆì´ë¯€ë¡œ ì‹ ìƒí’ˆì´ ì—†ì„ ìˆ˜ ìˆìŒ.
                # ê³„ì† ë’¤ë¡œ ê°€ì•¼ í•¨.
                print(f"  PASS í˜ì´ì§€ {page} (ê¸°ì¡´ ìƒí’ˆë“¤)")
                
            time.sleep(0.1)

        except Exception as e:
            print(f"âŒ ì—ëŸ¬: {e}")
            break
    
    # 3. ì‹ ìƒí’ˆë§Œ ì €ì¥ (bulk insert)
    if new_products:
        print(f"\nğŸ’¾ ì‹ ìƒí’ˆ {len(new_products)}ê°œ ì €ì¥ ì¤‘...")
        
        # ìˆœì„œëŒ€ë¡œ ì €ì¥ (ì˜¤ë˜ëœ ì‹ ìƒ -> ì•„ì£¼ ìµœì‹  ì‹ ìƒ)
        # new_products ë¦¬ìŠ¤íŠ¸ëŠ” ì´ë¯¸ ì˜¤ë¦„ì°¨ìˆœ(í˜ì´ì§€ ìˆœì„œëŒ€ë¡œ)ìœ¼ë¡œ ìŒ“ì˜€ìŒ.
        # ê·¸ëŒ€ë¡œ ë„£ìœ¼ë©´ ë¨.
        
        # ì²­í¬ ë‚˜ëˆ„ì–´ ì €ì¥
        for i in range(0, len(new_products), 50):
            chunk = new_products[i:i+50]
            supabase.table("new_products").insert(chunk).execute()
            
        print("ğŸ‰ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
    else:
        print("\nâœ¨ ìƒˆë¡œìš´ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤. ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
