import requests
from bs4 import BeautifulSoup
from supabase import create_client
import os
import time

# --- ì„¤ì • ---
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")

TARGET_CATEGORIES = ['40']  # ì•„ì´ìŠ¤í¬ë¦¼/ìŠ¤ë‚µ
MAX_PAGES = 5

def main():
    print("ğŸš€ CU í¬ë¡¤ëŸ¬ ì‹œì‘ (API ëª¨ë“œ)")

    if not SUPABASE_URL or not SUPABASE_KEY:
        print("âŒ ì—ëŸ¬: Supabase í™˜ê²½ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    # 1. ê¸°ì¡´ ë°ì´í„° ì´ˆê¸°í™”
    print("ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘...")
    try:
        supabase.table("new_products").delete().neq("id", 0).execute()
    except Exception as e:
        print(f"âš ï¸ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ ê°€ëŠ¥): {e}")

    all_products = []

    # 2. ì¹´í…Œê³ ë¦¬ë³„ í¬ë¡¤ë§ (ì •ìˆœ: 1â†’2â†’3â†’4â†’5)
    for cat_code in TARGET_CATEGORIES:
        print(f"\nğŸ“‚ ì¹´í…Œê³ ë¦¬ {cat_code} í¬ë¡¤ë§ ì‹œì‘...")
        
        for page in range(1, MAX_PAGES + 1):
            print(f"  - í˜ì´ì§€ {page} ìš”ì²­ ì¤‘...")
            
            url = "https://cu.bgfretail.com/product/productAjax.do"
            payload = {
                "pageIndex": page,
                "searchMainCategory": cat_code,
                "searchSubCategory": "",
                "listType": 0,
                "searchCondition": "setC",
                "searchUseYn": "N",
                "codeParent": cat_code
            }
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
            }

            try:
                response = requests.post(url, data=payload, headers=headers, timeout=10)
                response.encoding = 'utf-8'
                
                if response.status_code != 200:
                    print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
                    continue

                soup = BeautifulSoup(response.text, 'html.parser')
                items = soup.select("li.prod_list")

                if not items:
                    print("    â„¹ï¸ ë” ì´ìƒ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
                    break

                print(f"    âœ… {len(items)}ê°œ ì œí’ˆ ë°œê²¬")
                
                # ì²« í˜ì´ì§€ ì²« ì œí’ˆ í™•ì¸ (ë””ë²„ê¹…ìš©)
                if page == 1 and items:
                    first_title = items[0].select_one(".name p")
                    if first_title:
                        print(f"    ğŸ” í˜ì´ì§€ 1 ì²« ì œí’ˆ: {first_title.text.strip()}")

                for item in items:
                    try:
                        # 1. ì œí’ˆëª…
                        name_tag = item.select_one(".name p")
                        if not name_tag:
                            continue
                        title = name_tag.text.strip()

                        # 2. ê°€ê²©
                        price_tag = item.select_one(".price strong")
                        price_text = price_tag.text.strip().replace(",", "").replace("ì›", "") if price_tag else "0"
                        price = int(price_text) if price_text.isdigit() else 0

                        # 3. ì´ë¯¸ì§€ URL
                        img_tag = item.select_one("img")
                        image_url = ""
                        
                        if img_tag:
                            image_url = (
                                img_tag.get('src') or 
                                img_tag.get('data-src') or 
                                img_tag.get('data-original') or 
                                ""
                            )
                            
                            if image_url:
                                if image_url.startswith('//'):
                                    image_url = f"https:{image_url}"
                                elif image_url.startswith('/'):
                                    image_url = f"https://cu.bgfretail.com{image_url}"
                                elif not image_url.startswith('http'):
                                    image_url = f"https://cu.bgfretail.com/{image_url}"

                        # 4. ì¹´í…Œê³ ë¦¬ ë° í–‰ì‚¬ ì •ë³´
                        badge_tag = item.select_one(".badge")
                        promotion_type = badge_tag.text.strip() if badge_tag else None
                        
                        # âœ… ì‹¤ì œ ìƒí’ˆ ì¹´í…Œê³ ë¦¬ (ì¹´í…Œê³ ë¦¬ ì½”ë“œì— ë”°ë¼ ìë™ ë§¤í•‘)
                        category_map = {
                            '40': 'ì•„ì´ìŠ¤í¬ë¦¼',
                            '50': 'ê³¼ì',
                            '60': 'ìŒë£Œ',
                            # ì¶”ê°€ ì¹´í…Œê³ ë¦¬ëŠ” ì—¬ê¸°ì— ì¶”ê°€
                        }
                        category_name = category_map.get(cat_code, 'ê¸°íƒ€')

                        # 5. ìƒí’ˆ ìƒì„¸ ë§í¬
                        detail_link = item.select_one("a")
                        product_url = "https://cu.bgfretail.com/product/product.do"
                        if detail_link and detail_link.get('href'):
                            href = detail_link['href']
                            if href.startswith('http'):
                                product_url = href
                            elif href.startswith('/'):
                                product_url = f"https://cu.bgfretail.com{href}"
                            elif '?' in href or 'product' in href:
                                product_url = f"https://cu.bgfretail.com/product/{href}"

                        # âœ… categoryëŠ” ìƒí’ˆ ë¶„ë¥˜, promotion_typeì€ í–‰ì‚¬ ì •ë³´
                        product = {
                            "title": title,
                            "price": price,
                            "image_url": image_url,
                            "category": category_name,  # ì•„ì´ìŠ¤í¬ë¦¼, ê³¼ì, ìŒë£Œ ë“±
                            "promotion_type": promotion_type,  # 1+1, 2+1, ë¤ì¦ì • ë“± (ì—†ìœ¼ë©´ None)
                            "source_url": product_url,
                            "is_active": True,
                            "brand_id": 1
                        }
                        
                        all_products.append(product)

                    except Exception as e:
                        print(f"    âš ï¸ ì œí’ˆ íŒŒì‹± ì—ëŸ¬: {e}")
                        continue
                
                time.sleep(1)

            except Exception as e:
                print(f"âŒ í˜ì´ì§€ ìš”ì²­ ì—ëŸ¬: {e}")

    # 3. DB ì €ì¥ (ì—­ìˆœìœ¼ë¡œ ì €ì¥í•˜ì—¬ ì°°ì˜¥ìˆ˜ìˆ˜ê°€ ê°€ì¥ í° IDë¥¼ ë°›ë„ë¡)
    print(f"\nğŸ’¾ Supabaseì— ì €ì¥ ì¤‘... (ì´ {len(all_products)}ê°œ)")
    count = 0
    
    if all_products:
        print(f"  ğŸ” ì²« í¬ë¡¤ë§: {all_products[0]['title']}")
        print(f"  ğŸ”š ë§ˆì§€ë§‰ í¬ë¡¤ë§: {all_products[-1]['title']}")
        print(f"  âš™ï¸  ì—­ìˆœìœ¼ë¡œ ì €ì¥í•˜ì—¬ '{all_products[0]['title']}'ì´ ê°€ì¥ í° IDë¥¼ ë°›ìŠµë‹ˆë‹¤.")
    
    # ì—­ìˆœìœ¼ë¡œ ì €ì¥
    for product in reversed(all_products):
        try:
            supabase.table("new_products").insert(product).execute()
            count += 1
            if count % 10 == 0:
                print(f"  - {count}ê°œ ì €ì¥ ì™„ë£Œ...")
        except Exception as e:
            print(f"  âš ï¸ ì €ì¥ ì‹¤íŒ¨ ({product['title']}): {e}")

    print(f"\nğŸ‰ ì™„ë£Œ! ì´ {count}ê°œ ì œí’ˆì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ’¡ category: ìƒí’ˆ ë¶„ë¥˜, promotion_type: í–‰ì‚¬ ì •ë³´ë¡œ ë¶„ë¦¬ ì €ì¥ë¨")
    print(f"ğŸ’¡ ì•±ì—ì„œ ID DESC ì •ë ¬ ì‹œ '{all_products[0]['title']}'ì´ ë§¨ ìœ„ì— í‘œì‹œë©ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
