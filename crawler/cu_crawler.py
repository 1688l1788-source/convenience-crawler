import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import re
import os
from supabase import create_client
import time

class CUCrawler:
    def __init__(self):
        supabase_url = os.getenv('SUPABASE_URL')
        supabase_key = os.getenv('SUPABASE_SERVICE_KEY')
        
        if not supabase_url or not supabase_key:
            raise Exception("Supabase í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        self.supabase = create_client(supabase_url, supabase_key)
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        self.brand_id = 1  # CU
    
    def crawl(self):
        """CU ì‹ ì œí’ˆ í¬ë¡¤ë§"""
        print("ğŸª CU í¬ë¡¤ë§ ì‹œì‘...")
        
        # CU ì´ë²¤íŠ¸ ìƒí’ˆ í˜ì´ì§€ (ì‹¤ì œ URLì€ í™•ì¸ í•„ìš”)
        url = "https://cu.bgfretail.com/product/product.do?category=product&depth2=6&sf=N"
        
        try:
            response = requests.get(url, headers=self.headers, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            products = []
            
            # CU ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ì„ íƒì ì¡°ì • í•„ìš”
            # ì•„ë˜ëŠ” ì¼ë°˜ì ì¸ êµ¬ì¡° ì˜ˆì‹œ
            items = soup.select('.prodListWrap .prod_item')
            
            if not items:
                # ëŒ€ì²´ ì„ íƒì ì‹œë„
                items = soup.select('.product-list .product-item')
            
            print(f"ğŸ“¦ ë°œê²¬ëœ ìƒí’ˆ: {len(items)}ê°œ")
            
            for idx, item in enumerate(items[:20]):  # ìµœëŒ€ 20ê°œë§Œ
                try:
                    # ì œí’ˆëª…
                    title_elem = item.select_one('.prodName, .prod_name, .product-name')
                    if not title_elem:
                        continue
                    title = title_elem.text.strip()
                    
                    # ê°€ê²©
                    price_elem = item.select_one('.price, .prod_price, .product-price')
                    price = None
                    if price_elem:
                        price_text = price_elem.text.strip()
                        price_match = re.findall(r'\d+', price_text.replace(',', ''))
                        if price_match:
                            price = int(''.join(price_match))
                    
                    # ì´ë¯¸ì§€
                    img_elem = item.select_one('img')
                    image_url = None
                    if img_elem:
                        image_url = img_elem.get('src') or img_elem.get('data-src')
                        if image_url and not image_url.startswith('http'):
                            image_url = 'https://cu.bgfretail.com' + image_url
                    
                    # ë§í¬
                    link_elem = item.select_one('a')
                    source_url = url
                    if link_elem:
                        href = link_elem.get('href')
                        if href:
                            if href.startswith('http'):
                                source_url = href
                            elif href.startswith('/'):
                                source_url = 'https://cu.bgfretail.com' + href
                    
                    product = {
                        'brand_id': self.brand_id,
                        'title': title,
                        'normalized_title': self.normalize_title(title),
                        'price': price,
                        'category': self.categorize(title),
                        'launch_date': datetime.now().date().isoformat(),
                        'image_url': image_url,
                        'source_url': source_url,
                        'is_active': True
                    }
                    
                    products.append(product)
                    print(f"  âœ“ {idx+1}. {title[:30]}...")
                    
                except Exception as e:
                    print(f"  âœ— ìƒí’ˆ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue
            
            return products
            
        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return []
    
    def normalize_title(self, title):
        """ì œí’ˆëª… ì •ê·œí™”"""
        normalized = re.sub(r'\s+', ' ', title)
        normalized = re.sub(r'[^\w\sê°€-í£]', '', normalized)
        return normalized.strip().upper()
    
    def categorize(self, title):
        """ì¹´í…Œê³ ë¦¬ ìë™ ë¶„ë¥˜"""
        title_lower = title.lower()
        
        keywords = {
            'ìŒë£Œ': ['ìŒë£Œ', 'ì£¼ìŠ¤', 'ì»¤í”¼', 'ìš°ìœ ', 'ì°¨', 'ì›Œí„°', 'ì‚¬ì´ë‹¤', 'ì½œë¼'],
            'ê³¼ì': ['ê³¼ì', 'ì´ˆì½œë¦¿', 'ì‚¬íƒ•', 'ì ¤ë¦¬', 'ì¿ í‚¤', 'ë¹„ìŠ¤í‚·', 'ìŠ¤ë‚µ'],
            'ì¦‰ì„ì‹í’ˆ': ['ë„ì‹œë½', 'ê¹€ë°¥', 'ìƒŒë“œìœ„ì¹˜', 'ì‚¼ê°ê¹€ë°¥', 'í•«ë„ê·¸', 'í–„ë²„ê±°'],
            'ë¼ë©´': ['ë¼ë©´', 'ì»µë¼ë©´', 'ì§œíŒŒê²Œí‹°', 'ì§œì¥ë©´'],
            'ì•„ì´ìŠ¤í¬ë¦¼': ['ì•„ì´ìŠ¤í¬ë¦¼', 'ë¹™ê³¼', 'ì•„ì´ìŠ¤ë°”', 'ì½˜', 'íŒŒì¸íŠ¸']
        }
        
        for category, words in keywords.items():
            if any(word in title_lower for word in words):
                return category
        
        return 'ê¸°íƒ€'
    
    def save_to_db(self, products):
        """ì‹ ê·œ ì œí’ˆë§Œ DBì— ì €ì¥"""
        if not products:
            print("ğŸ’¤ ìˆ˜ì§‘ëœ ì œí’ˆ ì—†ìŒ")
            return 0
        
        print(f"\nğŸ’¾ DB ì €ì¥ ì‹œì‘...")
        
        try:
            # ìµœê·¼ 30ì¼ ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ
            thirty_days_ago = (datetime.now() - timedelta(days=30)).date().isoformat()
            
            existing = self.supabase.table('new_products')\
                .select('normalized_title, launch_date')\
                .eq('brand_id', self.brand_id)\
                .gte('launch_date', thirty_days_ago)\
                .execute()
            
            existing_keys = {
                f"{p['normalized_title']}_{p['launch_date']}" 
                for p in existing.data
            }
            
            # ì‹ ê·œ ì œí’ˆ í•„í„°ë§
            new_products = [
                p for p in products 
                if f"{p['normalized_title']}_{p['launch_date']}" not in existing_keys
            ]
            
            if new_products:
                # ë°°ì¹˜ë¡œ ì‚½ì…
                self.supabase.table('new_products').insert(new_products).execute()
                print(f"âœ… {len(new_products)}ê°œ ì‹ ì œí’ˆ ì €ì¥ ì™„ë£Œ")
                
                # ì €ì¥ëœ ì œí’ˆ ì¶œë ¥
                for p in new_products[:5]:
                    print(f"  - {p['title'][:40]}")
                if len(new_products) > 5:
                    print(f"  ... ì™¸ {len(new_products)-5}ê°œ")
                
                return len(new_products)
            else:
                print("â„¹ï¸  ì‹ ê·œ ì œí’ˆ ì—†ìŒ (ëª¨ë‘ ê¸°ì¡´ ì œí’ˆ)")
                return 0
                
        except Exception as e:
            print(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0

def main():
    print("="*60)
    print("ğŸª í¸ì˜ì  ì‹ ì œí’ˆ í¬ë¡¤ëŸ¬ ì‹œì‘")
    print(f"â° ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    try:
        crawler = CUCrawler()
        products = crawler.crawl()
        new_count = crawler.save_to_db(products)
        
        print("\n" + "="*60)
        print(f"âœ¨ í¬ë¡¤ë§ ì™„ë£Œ!")
        print(f"ğŸ“Š ìˆ˜ì§‘: {len(products)}ê°œ | ì‹ ê·œ: {new_count}ê°œ")
        print("="*60)
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        exit(1)

if __name__ == "__main__":
    main()
