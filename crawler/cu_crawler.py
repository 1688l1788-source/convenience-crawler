import os
import time
import re
import json
import requests
from bs4 import BeautifulSoup
from supabase import create_client

# ==========================================
# âš™ï¸ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
# ==========================================
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")

# ==========================================
# ğŸ§  í†µí•© ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ê¸° V2 (ì •ë°€ë„ ëŒ€í­ í–¥ìƒ)
# ==========================================
def get_standard_category(title, raw_category=None):
    # ì „ì²˜ë¦¬: ê³µë°± ì œê±° ë° ì†Œë¬¸ì ë³€í™˜ (ë§¤ì¹­ í™•ë¥  ë†’ì„)
    clean_title = title.replace(" ", "").lower()
    
    # [0] ì›ë³¸ ì¹´í…Œê³ ë¦¬ ì‹ ë¢° (ê°€ì¥ í™•ì‹¤í•¨)
    if raw_category:
        raw_map = {
            "ê°„í¸ì‹ì‚¬": "ê°„í¸ì‹ì‚¬", "ë„ì‹œë½": "ê°„í¸ì‹ì‚¬", "ê¹€ë°¥": "ê°„í¸ì‹ì‚¬", "ìƒŒë“œìœ„ì¹˜": "ê°„í¸ì‹ì‚¬", "í–„ë²„ê±°": "ê°„í¸ì‹ì‚¬",
            "ê³¼ìë¥˜": "ê³¼ìë¥˜", "ìŠ¤ë‚µ": "ê³¼ìë¥˜", "ê»Œ": "ê³¼ìë¥˜", "ìº”ë””": "ê³¼ìë¥˜", "ì´ˆì½œë¦¿": "ê³¼ìë¥˜",
            "ì•„ì´ìŠ¤í¬ë¦¼": "ì•„ì´ìŠ¤í¬ë¦¼", 
            "ìŒë£Œ": "ìŒë£Œ", "ìœ ì œí’ˆ": "ìŒë£Œ",
            "ìƒí™œìš©í’ˆ": "ìƒí™œìš©í’ˆ", "ìœ„ìƒìš©í’ˆ": "ìƒí™œìš©í’ˆ", "ì¡í™”": "ìƒí™œìš©í’ˆ",
            "ì‹í’ˆ": "ì‹í’ˆ", "ì•ˆì£¼ë¥˜": "ì‹í’ˆ", "ê°€ê³µì‹í’ˆ": "ì‹í’ˆ", "ë°˜ì°¬": "ì‹í’ˆ", "ì¦‰ì„ì¡°ë¦¬": "ì‹í’ˆ"
        }
        # CU/GSì—ì„œ ë‚´ë ¤ì˜¤ëŠ” ì¹´í…Œê³ ë¦¬ëª…ì´ raw_mapì— ìˆìœ¼ë©´ ë°”ë¡œ ë°˜í™˜
        for key, val in raw_map.items():
            if key in raw_category:
                return val

    # ==========================================
    # [1] ìƒí™œìš©í’ˆ (ë¸Œëœë“œ/í‚¤ì›Œë“œê°€ ë§¤ìš° ë…íŠ¹í•˜ë¯€ë¡œ 1ìˆœìœ„)
    # ==========================================
    life_keywords = [
        'ì¹˜ì•½', 'ì¹«ì†”', 'ê°€ê¸€', 'ê°€ê·¸ë¦°', 'í˜ë¦¬ì˜¤', '2080', 'ë¦¬ìŠ¤í…Œë¦°', # êµ¬ê°•
        'ìƒë¦¬ëŒ€', 'ì˜¤ë²„ë‚˜ì´íŠ¸', 'ë¼ì´ë„ˆ', 'íƒí°', 'ì˜í”¼', 'í™”ì´íŠ¸', 'ì¢‹ì€ëŠë‚Œ', 'ì…ëŠ”ì˜¤ë²„', # ì—¬ì„±
        'ìƒ´í‘¸', 'ë¦°ìŠ¤', 'íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸', 'ë°”ë””ì›Œì‹œ', 'í¼í´ë Œì§•', 'ë©´ë„ê¸°', 'ì™ìŠ¤', 'ë¡œì…˜', 'í•¸ë“œí¬ë¦¼', 'ë¦½ì¼€ì–´', 'ë‹ˆë² ì•„', # ë·°í‹°
        'ë¬¼í‹°ìŠˆ', 'ë¡¤í‹°ìŠˆ', 'í‚¤ì¹œíƒ€ì›”', 'ë§ˆìŠ¤í¬', 'ê±´ì „ì§€', 'ìš°ì‚°', 'ì–‘ë§', 'ìŠ¤íƒ€í‚¹', 'ì´ì–´í°', 'ì¶©ì „ê¸°',
        'íí', 'ì„¸ì œ', 'ì„¬ìœ ìœ ì—°ì œ', 'ë½ìŠ¤', 'ë°©ì¶©ì œ', 'ì œìŠµì œ', 'ì½˜ë”', 'ëŸ¬ë¸Œì ¤'
    ]
    if any(k in clean_title for k in life_keywords):
        return "ìƒí™œìš©í’ˆ"

    # ==========================================
    # [2] ë‹¨ìœ„(Unit) ê¸°ë°˜ ê°•ë ¥ í•„í„°ë§ (ìŒë£Œ vs ê³ ì²´ êµ¬ë¶„)
    # ==========================================
    # ml, l, ë¦¬í„° ë“±ìœ¼ë¡œ ëë‚˜ëŠ”ì§€ í™•ì¸ (ì˜ˆ: 500ml, 1.5l)
    is_liquid = re.search(r'\d+(ml|l|ë¦¬í„°)$', clean_title) or re.search(r'\d+(ml|l|ë¦¬í„°)[^\wê°€-í£]', clean_title)
    
    # ìŒë£Œ í‚¤ì›Œë“œ
    drink_keywords = [
        'ì•„ë©”ë¦¬ì¹´ë…¸', 'ë¼ë–¼', 'ì—ì´ë“œ', 'ì£¼ìŠ¤', 'ë³´ë¦¬ì°¨', 'ì˜¥ìˆ˜ìˆ˜ìˆ˜ì—¼ì°¨', 'í—›ê°œ', 
        'ë¹„íƒ€500', 'ë°•ì¹´ìŠ¤', 'ë‘ìœ ', 'ìš°ìœ ', 'ìš”êµ¬ë¥´íŠ¸', 'ì´ì˜¨', 'íƒ„ì‚°', 'ì½œë¼', 'ì‚¬ì´ë‹¤', 
        'ë§¥ì£¼', 'í•˜ì´ë³¼', 'ì†Œì£¼', 'ì™€ì¸', 'ì›Œí„°', 'ìƒìˆ˜', 'ì½¤ë¶€ì°¨', 'í† ë ˆíƒ€', 'ê²Œí† ë ˆì´', 
        'íŒŒì›Œì—ì´ë“œ', 'ë°€í‚¤ìŠ¤', 'ì›°ì¹˜ìŠ¤', 'ìŠ¤íƒ€ë²…ìŠ¤', 'ì¹¸íƒ€íƒ€', 'top', 'ë°”ë¦¬ìŠ¤íƒ€', 'í‹°ì˜¤í”¼'
    ]

    # ì•¡ì²´ ë‹¨ìœ„ê°€ ìˆê±°ë‚˜ ìŒë£Œ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìŒë£Œ (ë‹¨, ìƒ´í‘¸ ë“± ìƒí™œìš©í’ˆì€ ìœ„ì—ì„œ ì´ë¯¸ ê±¸ëŸ¬ì§)
    if is_liquid or any(k in clean_title for k in drink_keywords):
        # ì˜ˆì™¸: 'ìš°ìœ 'ê°€ ë“¤ì–´ê°”ì§€ë§Œ 'ì‹ë¹µ', 'í¬ë¦¼ë¹µ' ë“±ì¸ ê²½ìš° ë°©ì§€
        if not any(ex in clean_title for ex in ['ì‹ë¹µ', 'í¬ë¦¼ë¹µ', 'ìƒŒë“œ', 'ì¿ í‚¤', 'ë¹™ìˆ˜', 'íŒŒë¥´í˜', 'ìº”ë””', 'ì ¤ë¦¬']):
            return "ìŒë£Œ"

    # ==========================================
    # [3] ì•„ì´ìŠ¤í¬ë¦¼ (ì—¬ë¦„ì²  ì˜¤ë¶„ë¥˜ ë§ìŒ)
    # ==========================================
    ice_keywords = [
        'ì•„ì´ìŠ¤í¬ë¦¼', 'íŒŒì¸íŠ¸', 'ì½˜', 'ì„¤ë ˆì„', 'í´ë¼í¬', 'ìŠ¤í¬ë¥˜ë°”', 'ë¼ì§€ë°”', 
        'ë©”ë¡œë‚˜', 'ë¹„ë¹„ë¹…', 'ìŒìŒë°”', 'ë°”ë°¤ë°”', 'ì›”ë“œì½˜', 'ë¶€ë¼ë³´', 'êµ¬ìŠ¬ì•„ì´ìŠ¤', 
        'í•˜ê²ë‹¤ì¦ˆ', 'ë‚˜ëšœë£¨', 'ë²¤ì•¤ì œë¦¬ìŠ¤', 'ë¹µë¹ ë ˆ', 'ë”ìœ„ì‚¬ëƒ¥', 'ë¶•ì–´ì‹¸ë§Œì½”', 'ì°°ì˜¥ìˆ˜ìˆ˜',
        'ì†Œë¥´ë² ', 'ë¼ë¼ìŠ¤ìœ—', 'í—ˆì‰¬ì´ˆì½”ë°”', 'ì˜¥ë™ì'
    ]
    # 'ë°”'ë¡œ ëë‚˜ëŠ” ê²½ìš° ì²´í¬ (ë‹¨, í•«ë°”/ì—ë„ˆì§€ë°”/ì´ˆì½”ë°” ì œì™¸ ì£¼ì˜)
    # ì´ˆì½”ë°”ëŠ” ê³¼ìì¼ìˆ˜ë„ ì•„ì´ìŠ¤ì¼ìˆ˜ë„ ìˆìœ¼ë‚˜ ë³´í†µ ì•„ì´ìŠ¤ê°€ ë§ìŒ. í•˜ì§€ë§Œ ì—ë„ˆì§€ë°”ëŠ” ê³¼ì.
    ends_with_bar = clean_title.endswith('ë°”') and not any(k in clean_title for k in ['í•«ë°”', 'ì—ë„ˆì§€ë°”', 'í”„ë¡œí‹´ë°”', 'ì‹œë¦¬ì–¼ë°”', 'í›„ë‘í¬ë°”'])
    
    if ends_with_bar or any(k in clean_title for k in ice_keywords):
        return "ì•„ì´ìŠ¤í¬ë¦¼"

    # ==========================================
    # [4] ê°„í¸ì‹ì‚¬ (ë„ì‹œë½, ê¹€ë°¥ ë“±)
    # ==========================================
    meal_keywords = ['ë„ì‹œë½', 'ê¹€ë°¥', 'ì£¼ë¨¹ë°¥', 'ì‚¼ê°ê¹€ë°¥', 'ìƒŒë“œìœ„ì¹˜', 'í–„ë²„ê±°', 'ë²„ê±°', 'ì£½', 'ìƒëŸ¬ë“œ', 'íŒŒìŠ¤íƒ€', 'ìŠ¤íŒŒê²Œí‹°', 'ì»µë°˜']
    if any(k in clean_title for k in meal_keywords):
        # ì ¤ë¦¬(í–„ë²„ê±°ì ¤ë¦¬) ê°™ì€ í•¨ì • í”¼í•˜ê¸°
        if 'ì ¤ë¦¬' not in clean_title and 'ì‚¬íƒ•' not in clean_title:
            return "ê°„í¸ì‹ì‚¬"

    # ==========================================
    # [5] ê³¼ìë¥˜ vs ì‹í’ˆ (ê°€ì¥ ëª¨í˜¸í•œ ê²½ê³„)
    # ==========================================
    snack_keywords = [
        'ìŠ¤ë‚µ', 'ì ¤ë¦¬', 'ì‚¬íƒ•', 'ìº”ë””', 'ê»Œ', 'ì´ˆì½”', 'ì´ˆì½œë¦¿', 'ì¿ í‚¤', 'ì¹©', 'í¬ì¹´ì¹©', 'ìƒˆìš°ê¹¡',
        'ë¹„ìŠ¤í‚·', 'í¬ë˜ì»¤', 'ì•½ê³¼', 'ì–‘ê°±', 'íŒì½˜', 'í”„ë ˆì²¼', 'ì›¨í•˜ìŠ¤', 'ë§ˆì¹´ë¡±', 
        'ë¹µ', 'ë„ë„›', 'ì¼€ìµ', 'ì¹´ìŠ¤í…Œë¼', 'ì˜¤ì˜ˆìŠ¤', 'ëª½ì‰˜', 'ì´ˆì½”íŒŒì´', 'ì—ë„ˆì§€ë°”', 'í”„ë¡œí‹´ë°”'
    ]
    
    # ì‹í’ˆ í‚¤ì›Œë“œ (ì¡°ë¦¬ê°€ í•„ìš”í•˜ê±°ë‚˜ ë°˜ì°¬ë¥˜)
    food_keywords = [
        'ë¼ë©´', 'ìš°ë™', 'êµ­ìˆ˜', 'ìŒ€êµ­ìˆ˜', 'ì°Œê°œ', 'êµ­', 'íƒ•', 'í–‡ë°˜', 'ì»µë°˜', 'ì˜¤ëšœê¸°ë°¥', 
        'í•«ë°”', 'í›„ë‘í¬', 'ì†Œì‹œì§€', 'ë¹„ì—”ë‚˜', 'ë§Œë‘', 'êµì', 'ì¹˜í‚¨', 'ë‹­ê°€ìŠ´ì‚´', 
        'ì¡±ë°œ', 'í¸ìœ¡', 'ê³±ì°½', 'ì•ˆì£¼', 'ìœ¡í¬', 'ì–´ë¬µ', 'ë§›ì‚´', 'í¬ë˜ë¯¸', 'ë‘ë¶€', 'ê³„ë€', 'ê¹€ì¹˜',
        'ì§í™”', 'ê¼¬ì¹˜'
    ]

    # ê³¼ìë¥˜ ì²´í¬ (ì‹í’ˆë³´ë‹¤ ë¨¼ì € ì²´í¬í•˜ë˜, ì‹í’ˆ í‚¤ì›Œë“œê°€ ì„ì—¬ ìˆìœ¼ë©´ ì‹í’ˆ ìš°ì„ ì¼ ìˆ˜ ìˆìŒ)
    if any(k in clean_title for k in snack_keywords):
        return "ê³¼ìë¥˜"

    if any(k in clean_title for k in food_keywords):
        return "ì‹í’ˆ"

    # ==========================================
    # [6] ìµœí›„ì˜ ë³´ë£¨ (ê¸°íƒ€ ì²˜ë¦¬)
    # ==========================================
    # ì´ë¦„ì— 'ë°”'ê°€ í¬í•¨ë˜ê³  gë‹¨ìœ„ë©´ ë³´í†µ ì‹í’ˆ(í•«ë°”)ì´ë‚˜ ê³¼ì(ì´ˆì½”ë°”)
    # ìœ„ì—ì„œ ì•ˆ ê±¸ëŸ¬ì§„ 'ë°”+g'ëŠ” ì‹í’ˆìœ¼ë¡œ ê°„ì£¼ (ì˜ˆ: ìˆ¯ë¶ˆë°” 80g)
    if 'ë°”' in clean_title and 'g' in clean_title:
        return "ì‹í’ˆ"

    return "ê¸°íƒ€"

# ==========================================
# ğŸª 1. CU í¬ë¡¤ë§
# ==========================================
def parse_cu_product(item, raw_cat_name):
    try:
        name_tag = item.find("div", class_="name")
        if not name_tag: return None
        title = name_tag.get_text(strip=True)
        
        if raw_cat_name == "ì¦‰ì„ì¡°ë¦¬": return None # ì œì™¸

        price_tag = item.find("div", class_="price")
        price = int(price_tag.find("strong").get_text(strip=True).replace(",", "")) if price_tag else 0

        img_tag = item.find("img")
        img_src = ""
        if img_tag:
            img_src = img_tag.get("src") or ""
            if img_src and not img_src.startswith("http"):
                if img_src.startswith("//"): img_src = "https:" + img_src
                else: img_src = "https://cu.bgfretail.com" + img_src

        # NEW / í–‰ì‚¬ ê°ì§€
        is_new = False
        promo = "ì¼ë°˜"

        # 1. ì´ë¯¸ì§€ë¡œ NEW ê°ì§€
        for img in item.find_all("img"):
            if "tag_new.png" in img.get("src", ""):
                is_new = True
                break
        
        # 2. ë°°ì§€ í…ìŠ¤íŠ¸
        badge_tag = item.find("div", class_="badge")
        if badge_tag:
            if "NEW" in badge_tag.get_text(strip=True).upper(): is_new = True
            
            span = badge_tag.find("span")
            promo = span.get_text(strip=True) if span else badge_tag.get_text(strip=True)

        if "ë¤" in promo or "ì¦ì •" in promo: return None

        gdIdx = None
        onclick = item.find("div", onclick=re.compile(r"view\("))
        if onclick:
            m = re.search(r"view\s*\(\s*['\"]?(\d+)['\"]?\s*\)", onclick.get('onclick'))
            if m: gdIdx = int(m.group(1))
        
        if not gdIdx:
            # ë°±ì—…: photo div
            photo = item.find("div", class_="photo")
            if photo and photo.find("a"):
                m = re.search(r"view\s*\(\s*['\"]?(\d+)['\"]?\s*\)", photo.find("a").get('onclick', ''))
                if m: gdIdx = int(m.group(1))

        if not gdIdx: return None

        std_category = get_standard_category(title, raw_cat_name)

        return {
            "title": title,
            "price": price,
            "image_url": img_src,
            "category": std_category,
            "original_category": raw_cat_name,
            "promotion_type": promo,
            "brand_id": 1,
            "source_url": f"https://cu.bgfretail.com/product/view.do?category=product&gdIdx={gdIdx}",
            "is_active": True,
            "external_id": gdIdx,
            "is_new": is_new
        }
    except: return None

def crawl_cu(supabase):
    print("\nğŸš€ CU í¬ë¡¤ë§ ì‹œì‘...")
    supabase.table("new_products").delete().eq("brand_id", 1).execute()

    cu_categories = [
        {"id": "10", "name": "ê°„í¸ì‹ì‚¬"}, {"id": "30", "name": "ê³¼ìë¥˜"},
        {"id": "40", "name": "ì•„ì´ìŠ¤í¬ë¦¼"}, {"id": "50", "name": "ì‹í’ˆ"},
        {"id": "60", "name": "ìŒë£Œ"}, {"id": "70", "name": "ìƒí™œìš©í’ˆ"}
    ]
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "Referer": "https://cu.bgfretail.com"
    }
    
    all_items = []
    for cat in cu_categories:
        print(f"ğŸ” CU ì¡°íšŒ: {cat['name']}")
        for page in range(1, 21):
            try:
                r = requests.post("https://cu.bgfretail.com/product/productAjax.do", 
                                data={"pageIndex": page, "searchMainCategory": cat['id'], "listType": 0},
                                headers=headers, timeout=10)
                r.encoding = 'utf-8'
                soup = BeautifulSoup(r.text, "html.parser")
                items = soup.select("li.prod_list")
                if not items: break
                
                for item in items:
                    p = parse_cu_product(item, cat['name'])
                    if p: all_items.append(p)
                time.sleep(0.1)
            except: break

    if all_items:
        print(f"âœ… CU {len(all_items)}ê°œ ì €ì¥ ì¤‘...")
        unique = {p['external_id']: p for p in all_items}.values()
        items_list = list(unique)
        for i in range(0, len(items_list), 100):
            supabase.table("new_products").insert(items_list[i:i+100]).execute()
        print("ğŸ‰ CU ì™„ë£Œ")

# ==========================================
# ğŸª 2. GS25 í¬ë¡¤ë§
# ==========================================
def get_gs25_token():
    session = requests.Session()
    session.headers.update({
        "User-Agent": "Mozilla/5.0", "Referer": "https://gs25.gsretail.com/gscvs/ko/products/event-goods"
    })
    for i in range(3):
        try:
            r = session.get("https://gs25.gsretail.com/gscvs/ko/products/event-goods", timeout=15)
            soup = BeautifulSoup(r.text, "html.parser")
            token = soup.find("input", {"name": "CSRFToken"})
            if token and token.get('value'): return session, token['value']
            time.sleep(1)
        except: pass
    return session, None

def crawl_gs25(supabase):
    print("\nğŸš€ GS25 í¬ë¡¤ë§ ì‹œì‘...")
    session, token = get_gs25_token()
    if not token: 
        print("âŒ GS25 í† í° ì‹¤íŒ¨")
        return

    session.headers.update({"Accept": "application/json", "X-Requested-With": "XMLHttpRequest"})
    all_items = []

    for p_type in ["ONE_TO_ONE", "TWO_TO_ONE"]:
        print(f"ğŸ” GS25 ì¡°íšŒ: {p_type}")
        for page in range(1, 20):
            try:
                r = session.post("https://gs25.gsretail.com/gscvs/ko/products/event-goods-search",
                               data={"CSRFToken": token, "pageNum": str(page), "pageSize": "50", "parameterList": p_type})
                data = json.loads(r.text) if not isinstance(r.json(), dict) else r.json()
                results = data.get("results", [])
                if not results: break
                
                for item in results:
                    title = item.get("goodsNm", "").strip()
                    price = int(item.get("price", 0))
                    att_id = item.get("attFileId", "")
                    id_match = re.search(r'(\d+)', att_id)
                    ext_id = int(id_match.group(1)[-18:]) if id_match else int(time.time()*1000)
                    promo_map = {"ONE_TO_ONE": "1+1", "TWO_TO_ONE": "2+1"}
                    
                    all_items.append({
                        "title": title,
                        "price": price,
                        "image_url": item.get("attFileNm", ""),
                        "category": get_standard_category(title, None), # GSëŠ” í‚¤ì›Œë“œ ë¶„ë¥˜
                        "original_category": None,
                        "promotion_type": promo_map.get(p_type, "í–‰ì‚¬"),
                        "brand_id": 2,
                        "source_url": "http://gs25.gsretail.com/gscvs/ko/products/event-goods",
                        "is_active": True,
                        "external_id": ext_id,
                        "is_new": False
                    })
                time.sleep(0.1)
            except: break

    if all_items:
        print(f"âœ… GS25 {len(all_items)}ê°œ ì €ì¥ ì¤‘...")
        supabase.table("new_products").delete().eq("brand_id", 2).execute()
        unique = {p['external_id']: p for p in all_items}.values()
        items_list = list(unique)
        for i in range(0, len(items_list), 100):
            supabase.table("new_products").insert(items_list[i:i+100]).execute()
        print("ğŸ‰ GS25 ì™„ë£Œ")

def main():
    if not SUPABASE_URL or not SUPABASE_KEY: return
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    # ğŸ§¹ ë¤ì¦ì • ì‚­ì œ
    try:
        supabase.table("new_products").delete().or_("promotion_type.eq.ë¤,promotion_type.eq.ë¤ì¦ì •,promotion_type.ilike.%GIFT%").execute()
    except: pass

    crawl_cu(supabase)
    crawl_gs25(supabase)
    print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")

if __name__ == "__main__":
    main()
