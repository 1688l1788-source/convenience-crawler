import os
import time
import re
import requests
from bs4 import BeautifulSoup
from supabase import create_client
import urllib3

# SSL ê²½ê³  ë¬´ì‹œ (ì„¸ë¸ì¼ë ˆë¸ êµ¬í˜• ì„œë²„ í˜¸í™˜ì„±)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    print("âŒ í™˜ê²½ë³€ìˆ˜(SUPABASE_URL, SUPABASE_KEY)ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    exit()

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# --- ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ê¸° (ê¸°ì¡´ ë¡œì§ ìœ ì§€) ---
def get_standard_category(title, raw_category=None):
    if raw_category == "ê°„í¸ì‹ì‚¬": return "ê°„í¸ì‹ì‚¬"
    
    # 1. ìƒí™œìš©í’ˆ
    if any(k in title for k in ['ì¹˜ì•½', 'ì¹«ì†”', 'ê°€ê¸€', 'ìƒë¦¬ëŒ€', 'ìƒ´í‘¸', 'ë¦°ìŠ¤', 'ë©´ë„ê¸°', 'ë¬¼í‹°ìŠˆ', 'ë§ˆìŠ¤í¬', 'ìŠ¤íƒ€í‚¹', 'ê±´ì „ì§€', 'ë¹„ëˆ„', 'ë¡œì…˜', 'ë¦½ì¼€ì–´', 'ì„¸ì œ', 'ë½ìŠ¤', 'ìš°ì‚°', 'ì–‘ë§']):
        return "ìƒí™œìš©í’ˆ"
    # 2. ê°„í¸ì‹ì‚¬
    if any(k in title for k in ['ë„ì‹œë½', 'ê¹€ë°¥', 'ì£¼ë¨¹ë°¥', 'ìƒŒë“œìœ„ì¹˜', 'í–„ë²„ê±°', 'ë²„ê±°', 'ìƒëŸ¬ë“œ']):
        return "ê°„í¸ì‹ì‚¬"
    # 3. ì‹í’ˆ
    if re.search(r'ë°”\s*\d+g', title) or any(k in title for k in ['ë¼ë©´', 'ìš°ë™', 'êµ­ìˆ˜', 'í–‡ë°˜', 'í•«ë°”', 'í›„ë‘í¬', 'ì†Œì‹œì§€', 'ë§Œë‘', 'ì¹˜í‚¨', 'ìœ¡ê°œì¥', 'ì£½', 'íƒ•', 'ì°Œê°œ']):
        return "ì‹í’ˆ"
    # 4. ê³¼ìë¥˜
    if any(k in title for k in ['ìŠ¤ë‚µ', 'ì ¤ë¦¬', 'ì‚¬íƒ•', 'ê»Œ', 'ì´ˆì½”', 'ì¿ í‚¤', 'ì¹©', 'ë¹µ', 'ì•½ê³¼', 'ì–‘ê°±', 'íŒì½˜', 'ì•„ëª¬ë“œ']):
        return "ê³¼ìë¥˜"
    # 5. ì•„ì´ìŠ¤
    if title.endswith('ë°”') or any(k in title for k in ['í•˜ê²', 'ì†Œë¥´ë² ', 'ë‚˜ëšœë£¨', 'ì•„ì´ìŠ¤', 'ì½˜', 'íŒŒì¸íŠ¸', 'ì„¤ë ˆì„', 'í´ë¼í¬', 'ìŠ¤í¬ë¥˜', 'ë¼ì§€ë°”', 'ë¹™ìˆ˜', 'êµ¬ìŠ¬', 'ë¹µë¹ ë ˆ']):
        return "ì•„ì´ìŠ¤"
    # 6. ìŒë£Œ
    if any(k in title for k in ['ìš°ìœ ', 'ì»¤í”¼', 'ë¼ë–¼', 'ì½œë¼', 'ì‚¬ì´ë‹¤', 'ì—ì´ë“œ', 'ì£¼ìŠ¤', 'ë³´ë¦¬ì°¨', 'ë¹„íƒ€', 'ë°•ì¹´ìŠ¤', 'ë‘ìœ ', 'ìš”ê±°íŠ¸', 'ë¬¼', 'ì›Œí„°', 'ë§¥ì£¼', 'í•˜ì´ë³¼']):
        return "ìŒë£Œ"
    
    return "ê¸°íƒ€"

# --- ì„¸ë¸ì¼ë ˆë¸ íŒŒì‹± í•¨ìˆ˜ ---
def parse_seven_eleven(item, fixed_category=None):
    try:
        name_tag = item.find("div", class_="tit_product")
        if not name_tag: return None
        title = name_tag.get_text(strip=True)

        price_tag = item.find("div", class_="price")
        price = 0
        if price_tag:
            span = price_tag.find("span")
            if span:
                price = int(span.get_text(strip=True).replace(",", ""))

        img_tag = item.find("div", class_="pic_product").find("img")
        img_src = ""
        if img_tag:
            img_src = img_tag.get("src")
            if img_src and not img_src.startswith("http"):
                img_src = "https://www.7-eleven.co.kr" + img_src

        promo = "ì¼ë°˜"
        tag_list = item.find("ul", class_="tag_list_01")
        if tag_list:
            for tag in tag_list.find_all("li"):
                text = tag.get_text(strip=True)
                if "1+1" in text: promo = "1+1"
                elif "2+1" in text: promo = "2+1"
                elif "ì‹ ìƒí’ˆ" in text: promo = "NEW"

        gdIdx = None
        link = item.find("a", href=True)
        if link:
            m = re.search(r"fncGoView\('(\d+)'\)", link['href'])
            if m: gdIdx = int(m.group(1))
        
        if not gdIdx: return None

        return {
            "title": title,
            "price": price,
            "image_url": img_src,
            "category": fixed_category if fixed_category else get_standard_category(title, None),
            "original_category": fixed_category,
            "promotion_type": promo,
            "brand_id": 3,
            "source_url": f"https://www.7-eleven.co.kr/product/productView.asp?pCd={gdIdx}",
            "is_active": True,
            "external_id": gdIdx,
            "is_new": (promo == "NEW")
        }
    except Exception as e:
        print(f"   âš ï¸ íŒŒì‹± ì—ëŸ¬: {e}")
        return None

# --- í¬ë¡¤ë§ ë©”ì¸ ë¡œì§ ---
def run_seven_debug():
    print("\nğŸš€ 7-Eleven í¬ë¡¤ë§ (ë””ë²„ê·¸ ëª¨ë“œ) ì‹œì‘...")
    
    # ì„¸ë¸ì¼ë ˆë¸ì€ í—¤ë”ê°€ ë§¤ìš° ì¤‘ìš”í•¨
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "Origin": "https://www.7-eleven.co.kr",
        "Accept": "*/*",
        "X-Requested-With": "XMLHttpRequest"
    }

    all_items = []

    # 1. ë„ì‹œë½ (Fresh Food)
    print("\n[1] ë„ì‹œë½(Fresh Food) í…ŒìŠ¤íŠ¸")
    headers["Referer"] = "https://www.7-eleven.co.kr/product/bestdosirakList.asp"
    
    for page in range(1, 3): # í…ŒìŠ¤íŠ¸ë¡œ 2í˜ì´ì§€ë§Œ
        print(f"   ğŸ“„ í˜ì´ì§€ {page} ìš”ì²­ ì¤‘...", end=" ")
        try:
            r = requests.post("https://www.7-eleven.co.kr/product/dosirakNewMoreAjax.asp",
                            data={"intPageSize": 10, "intCurrPage": page},
                            headers=headers, timeout=15, verify=False)
            
            print(f"ì‘ë‹µì½”ë“œ: {r.status_code}, ê¸¸ì´: {len(r.text)}")
            
            if r.status_code != 200 or not r.text.strip():
                print("   âŒ ì‘ë‹µì´ ë¹„ì–´ìˆê±°ë‚˜ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                continue

            soup = BeautifulSoup(r.text, "html.parser")
            items = soup.find_all("li")
            
            if not items:
                print("   âŒ li íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (HTML êµ¬ì¡° ë³€ê²½ ê°€ëŠ¥ì„±)")
                # ë””ë²„ê¹…ìš©: HTML ì•ë¶€ë¶„ ì¶œë ¥
                print(f"   ğŸ” HTML ìƒ˜í”Œ: {r.text[:200]}")
                break
                
            count = 0
            for item in items:
                if "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤" in item.get_text(): 
                    print("   â„¹ï¸ ë°ì´í„° ì—†ìŒ ë©”ì‹œì§€ ë°œê²¬")
                    break
                p = parse_seven_eleven(item, fixed_category="ê°„í¸ì‹ì‚¬")
                if p:
                    all_items.append(p)
                    count += 1
            print(f"   âœ… {count}ê°œ ì•„ì´í…œ íŒŒì‹± ì„±ê³µ")
            
        except Exception as e:
            print(f"   âŒ ìš”ì²­ ì¤‘ ì—ëŸ¬: {e}")

    # 2. í–‰ì‚¬ ìƒí’ˆ (1+1, 2+1)
    print("\n[2] í–‰ì‚¬ ìƒí’ˆ í…ŒìŠ¤íŠ¸")
    headers["Referer"] = "https://www.7-eleven.co.kr/product/presentList.asp"
    
    for tab_id, promo_name in {1: "1+1", 2: "2+1"}.items():
        print(f"   ğŸ” {promo_name} (Tab {tab_id}) ì¡°íšŒ")
        for page in range(1, 3): # í…ŒìŠ¤íŠ¸ë¡œ 2í˜ì´ì§€ë§Œ
            try:
                r = requests.post("https://www.7-eleven.co.kr/product/listMoreAjax.asp",
                                data={"intPageSize": 10, "intCurrPage": page, "pTab": tab_id},
                                headers=headers, timeout=15, verify=False)
                
                if not r.text.strip(): 
                    print("   âŒ ì‘ë‹µ ì—†ìŒ")
                    break
                    
                soup = BeautifulSoup(r.text, "html.parser")
                items = soup.find_all("li")
                
                count = 0
                for item in items:
                    if "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤" in item.get_text(): break
                    p = parse_seven_eleven(item, fixed_category=None)
                    if p:
                        p['promotion_type'] = promo_name
                        all_items.append(p)
                        count += 1
                print(f"      ğŸ“„ í˜ì´ì§€ {page}: {count}ê°œ")
                
            except Exception as e:
                print(f"      âŒ ì—ëŸ¬: {e}")

    # ì €ì¥ í…ŒìŠ¤íŠ¸
    if len(all_items) > 0:
        print(f"\nğŸ’¾ ì´ {len(all_items)}ê°œ ë°ì´í„° Upsert ì‹œë„...")
        try:
            # ì¤‘ë³µ ì œê±°
            unique_items = {p['external_id']: p for p in all_items}.values()
            items_list = list(unique_items)
            
            # Upsert
            for i in range(0, len(items_list), 100):
                chunk = items_list[i:i+100]
                supabase.table("new_products").upsert(chunk, on_conflict="brand_id,external_id").execute()
            print("ğŸ‰ DB ì €ì¥ ì„±ê³µ!")
        except Exception as e:
            print(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
    else:
        print("\nğŸ˜± ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤. ìœ„ì˜ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    run_seven_debug()
